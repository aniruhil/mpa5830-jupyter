{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6920149b-f37b-48c2-9a4f-dd4e2fbdc7b3",
   "metadata": {},
   "source": [
    "# MPA 5830 - Module 01 (Fall 2021)\n",
    "\n",
    "#### What will you learn?\n",
    "In this module you will learn how to \n",
    "\n",
    "(a) access data files in R, both locally (i.e., from a folder on your computer) and from the web (i.e., without manually downloading a data file);\n",
    "\n",
    "(b) explore the contents of a data file with specific comands, \n",
    "\n",
    "(c) add value labels and create a new qualitative variable, \n",
    "\n",
    "(d) save data files in native R format, \n",
    "\n",
    "(e) load RData files, and\n",
    "\n",
    "(f) create, populate, and save a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eca76a-d664-4fa4-a5fe-0c1ebc8afde1",
   "metadata": {},
   "source": [
    "Base R comes bundled with some built-in functions (pieces of computer code) that do a variety of things. But one often needs additional pieces of computer code to accomplish a task. Often, base R could dprobably have done the task but we might be able to complete the task faster\\easier by relying on these additional pieces of computer code. You will see these additioal pieces of code being used time to time, and we call these little bundles of code __packages__.\n",
    "\n",
    "We start by loading up a package -- [tidyverse](https://www.tidyverse.org/) -- \"an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\" \n",
    "\n",
    "Well, what exactly is a __package__ in the R language? A package is best thought of as a collection of R functions, data, and documentation that explains what each function does. R has over 14,000 packages, each designed to do something very specific such as, for example, make maps, read large data files very speedily, make animated graphics, and so on. \n",
    "\n",
    "Each week you will see several new packages come into play because we will be relying on each to do something very specific for us. The __tidyverse__ will be a regular feature. \n",
    "\n",
    "How do we load a package? Well, first it has to be installed, but that has been taken care of for you. Once installed, we load it via the `library(packaganame)` command, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34598b",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "\n",
    "body{ /* Normal  */\n",
    "/*      font-family: Lato, sans-serif;  \n",
    "      font-family: Mukta, sans-serif; \n",
    "      font-family: 'Nunito Sans', sans-serif;\n",
    "      font-family: Karla, sans-serif;  */\n",
    "      font-family: 'Merriweather Sans', sans-serif; \n",
    "      font-size: 18px;\n",
    "  }\n",
    "\n",
    "h1.title {\n",
    "  font-size: 38px;\n",
    "  color: DarkRed;\n",
    "}\n",
    "h1 { /* Header 1 */\n",
    "  font-size: 28px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "h2 { /* Header 2 */\n",
    "    font-size: 22px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "h3 { /* Header 3 */\n",
    "  font-size: 18px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "code.r{ /* Code block */\n",
    "    font-family: Mukta, sans-serif; \n",
    "    font-weight: 600;\n",
    "    font-size: 16px;\n",
    "}\n",
    "/* pre { /* Code block - determines code spacing between lines */\n",
    "    font-size: 16px;\n",
    "} */\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c47f41",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: remotes\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.4     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.0.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c68ab-a1c6-4616-a2b3-40bc07ea7ae1",
   "metadata": {},
   "source": [
    "The message you see with a pinkish background results from our `library(tidyverse)` command, and is just a message indicating what packages were loaded (`ggplot2, tibble, tidyr, readr, purr, dplyr, stringr, forcats`), and if there is anything else we should be aware of. In this case, there is -- some commands (`filter()` and `lag()`) used by the `dplyr` package conflict with identically named commands in the `stats` package. \n",
    "\n",
    "`readr` is an excellent package designed to read data that might be available in various formats. Since it is loaded as a part of the `tidyverse`, let us move on to seeing how to read data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07b901",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "One of the golden rules to follow when reading data is to make your life easy by not having to memorize or discover through frantic trial-and-error runs where a particular data file is located. So how do we make our life easy? By placing all __data__ in a data folder. \n",
    "\n",
    "\n",
    "Data come in several formats but I will walk you through the formats you are most likely to encounter -- MS Excel, CSV, TXT, fixed-width, and then in any one of these commercial software formats: SAS, Stata, or SPSS. \n",
    "\n",
    "### CSV data files \n",
    "We start by reading a simple `comma-separated variable` format file and then a `tab-delimited variable` format file. A CSV file has each column separated by a `comma` while a tab-delimited file has every column separated by a `tab` -- `,` versus `\\t` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88f0a3ea-017c-4c7d-9065-333ed115addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here() starts at /Users/ruhil/Documents/github/mpa5830-fa21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3170dde",
   "metadata": {
    "eval": true,
    "name": "csvtab"
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in here(\"data\", \"ImportDataCSV.csv\"): could not find function \"here\"\n",
     "output_type": "error",
     "traceback": [
      "Error in here(\"data\", \"ImportDataCSV.csv\"): could not find function \"here\"\nTraceback:\n",
      "1. read_csv(here(\"data\", \"ImportDataCSV.csv\"))",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. standardise_path(file)"
     ]
    }
   ],
   "source": [
    "read_csv(\n",
    "  here(\"data\", \"ImportDataCSV.csv\")\n",
    "  ) -> df.csv \n",
    "\n",
    "read.csv(\n",
    "  \"data/ImportDataTAB.txt\",\n",
    "  sep = \"\\t\",\n",
    "  header = TRUE\n",
    "  ) -> df.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1513fb",
   "metadata": {},
   "source": [
    "Note ... \n",
    "* \"data/ImportDataCSV.csv\" specifies the specific file that should be read from the data folder.  \n",
    "* The `sep = \",\"` switch says the individual variables are separated by a comma \n",
    "* `header = TRUE` switch indicates that the first row in the file that is being read in has the column names  \n",
    "* The tab-delimited file needs `sep = \"\\t\"` because the columns are separated by a tab \n",
    "\n",
    "If no errors are thrown, then the files should have been read into memory and we can check their contents. The `names(filename)` command will show you the column names, and `glimpse(filename)` will show you a snippet of the data in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89329079-18cd-41ac-8069-9d5368db3ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'x'</li><li>'y'</li><li>'z'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'x'\n",
       "\\item 'y'\n",
       "\\item 'z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'x'\n",
       "2. 'y'\n",
       "3. 'z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"x\" \"y\" \"z\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 7\n",
      "Columns: 3\n",
      "$ x \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1, 4, 7, 10, 13, 16, 19\n",
      "$ y \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2, 5, 8, 11, 14, 17, 20\n",
      "$ z \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 3, 6, 9, 12, 15, 18, 21\n"
     ]
    }
   ],
   "source": [
    "names(df.csv) \n",
    "\n",
    "glimpse(df.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b443792-89d2-43e2-a0c4-8e17f6a93316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'x'</li><li>'y'</li><li>'z'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'x'\n",
       "\\item 'y'\n",
       "\\item 'z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'x'\n",
       "2. 'y'\n",
       "3. 'z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"x\" \"y\" \"z\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 7\n",
      "Columns: 3\n",
      "$ x \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1, 4, 7, 10, 13, 16, 19\n",
      "$ y \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2, 5, 8, 11, 14, 17, 20\n",
      "$ z \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 3, 6, 9, 12, 15, 18, 21\n"
     ]
    }
   ],
   "source": [
    "# And now we repeat the preceding commands for the df.tab file\n",
    "\n",
    "names(df.tab)\n",
    "\n",
    "glimpse(df.tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d3061",
   "metadata": {},
   "source": [
    "## MS Excel files\n",
    "\n",
    "Microsoft **Excel** files can be read via the `readxl` package, and you see two versions below -- one for the older `*.xls` format and the other for the newer `*.xlsx` format. \n",
    "\n",
    "As a rule, I would recommend against storing data in Excel formats since Excel tends to do some funny things. If you must store and share data, try to use the CSV format.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429261ec",
   "metadata": {
    "eval": true,
    "name": "excel"
   },
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "read_excel(\n",
    "  \"data/ImportDataXLS.xls\"\n",
    "  ) -> df.xls \n",
    "\n",
    "read_excel(\n",
    "  \"data/ImportDataXLSX.xlsx\"\n",
    "  ) -> df.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e9e9e1-b025-4996-beb3-919a440bcde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'x'</li><li>'y'</li><li>'z'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'x'\n",
       "\\item 'y'\n",
       "\\item 'z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'x'\n",
       "2. 'y'\n",
       "3. 'z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"x\" \"y\" \"z\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'x'</li><li>'y'</li><li>'z'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'x'\n",
       "\\item 'y'\n",
       "\\item 'z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'x'\n",
       "2. 'y'\n",
       "3. 'z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"x\" \"y\" \"z\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 7\n",
      "Columns: 3\n",
      "$ x \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 4, 7, 10, 13, 16, 19\n",
      "$ y \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 2, 5, 8, 11, 14, 17, 20\n",
      "$ z \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 3, 6, 9, 12, 15, 18, 21\n",
      "Rows: 7\n",
      "Columns: 3\n",
      "$ x \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 4, 7, 10, 13, 16, 19\n",
      "$ y \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 2, 5, 8, 11, 14, 17, 20\n",
      "$ z \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 3, 6, 9, 12, 15, 18, 21\n"
     ]
    }
   ],
   "source": [
    "names(df.xls)\n",
    "\n",
    "names(df.xlsx)\n",
    "\n",
    "glimpse(df.xlsx)\n",
    "\n",
    "glimpse(df.xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f52871",
   "metadata": {},
   "source": [
    "## SPSS, Stata, SAS files\n",
    "Some governmental agencies and other sources tend to use SAS, Stata, or SPSS for storing data and for carrying out various data analyses. This is a legacy issue that is changing but a little too slowly for most of us who do not use these commercial software packages as the mainstays of our data work. But, even if you do not use these packages, you should know how to read in data created in their native formats. As it turns out, **SPSS, Stata, SAS** files can be read via the `haven` package, and with relative ease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3af7ab3",
   "metadata": {
    "eval": true,
    "name": "others"
   },
   "outputs": [],
   "source": [
    "library(haven)\n",
    "\n",
    "read_stata(\n",
    "  \"data/ImportDataStata.dta\"\n",
    "  ) -> df.stata\n",
    "\n",
    "read_sas(\n",
    "  \"data/ImportDataSAS.sas7bdat\"\n",
    "  ) -> df.sas\n",
    "\n",
    "read_sav(\n",
    "  \"data/ImportDataSPSS.sav\"\n",
    "  ) -> df.spss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a087c6-d798-472e-bba1-a149e45bfe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'x'</li><li>'y'</li><li>'z'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'x'\n",
       "\\item 'y'\n",
       "\\item 'z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'x'\n",
       "2. 'y'\n",
       "3. 'z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"x\" \"y\" \"z\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 7\n",
      "Columns: 3\n",
      "$ x \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 4, 7, 10, 13, 16, 19\n",
      "$ y \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 2, 5, 8, 11, 14, 17, 20\n",
      "$ z \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 3, 6, 9, 12, 15, 18, 21\n"
     ]
    }
   ],
   "source": [
    "# Check the files\n",
    "\n",
    "names(df.stata)\n",
    "\n",
    "glimpse(df.sas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebafbd41",
   "metadata": {},
   "source": [
    "## Fixed-width files \n",
    "It is also common to encounter **fixed-width** files where the raw data are stored without any gaps between successive columns. This is also a legacy format from the early days of computers and punch cards, and one of the most efficient ways of storing large amounts of data. These files come with documentation that will give you the necessary details about where each column starts and ends, etc. [See here for some examples of layouts from the Census Bureau](https://www.census.gov/programs-surveys/geography/technical-documentation/records-layout/2010-zcta-record-layout.html#par_textimage_0).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d7d9c5",
   "metadata": {
    "eval": true,
    "name": "dfw"
   },
   "outputs": [],
   "source": [
    "read.fwf(\n",
    "  \"data/fwfdata.txt\",\n",
    "  widths = c(4, 9, 2, 4),\n",
    "  header = FALSE,\n",
    "  col.names = c(\"Name\", \"Month\", \"Day\", \"Year\")\n",
    "  ) -> df.fw "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27104e75",
   "metadata": {},
   "source": [
    "Notice we need `widths = c(4,9,2,4)` to indicate how many slots each column takes and then `col.names = c(\"Name\", \"Month\", \"Day\", \"Year\")` to label the columns since the data file does not have variable names. if you mess up with `widths = ` you end up with garbage because R does not know where any column starts or ends so be careful.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0f1e2b-30c2-4570-a63a-4c343435cf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2\n",
      "Columns: 4\n",
      "$ Name  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Amy \", \"Abby\"\n",
      "$ Month \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \" December\", \" December\"\n",
      "$ Day   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1, 11\n",
      "$ Year  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2017, 2017\n"
     ]
    }
   ],
   "source": [
    "glimpse(df.fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ae283",
   "metadata": {},
   "source": [
    "# Reading Files from the Web\n",
    "One of the benefits of software like R is its ability to read data files over the web __without requiring you to manually download the file and save a physical copy to be read in__. Specifically, it is possible to list the full web-path for a file and read it in. This ability is invaluable when the data tend to be periodically updated by the source (for example, by the Census Bureau, Bureau of Labor, Bureau of Economic Analysis, etc.). Here are a few examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96942516",
   "metadata": {
    "eval": true,
    "name": "readfiles"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 20 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>setting</th><th scope=col>effort</th><th scope=col>change</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Bolivia</th><td>46</td><td> 0</td><td> 1</td></tr>\n",
       "\t<tr><th scope=row>Brazil</th><td>74</td><td> 0</td><td>10</td></tr>\n",
       "\t<tr><th scope=row>Chile</th><td>89</td><td>16</td><td>29</td></tr>\n",
       "\t<tr><th scope=row>Colombia</th><td>77</td><td>16</td><td>25</td></tr>\n",
       "\t<tr><th scope=row>CostaRica</th><td>84</td><td>21</td><td>29</td></tr>\n",
       "\t<tr><th scope=row>Cuba</th><td>89</td><td>15</td><td>40</td></tr>\n",
       "\t<tr><th scope=row>DominicanRep</th><td>68</td><td>14</td><td>21</td></tr>\n",
       "\t<tr><th scope=row>Ecuador</th><td>70</td><td> 6</td><td> 0</td></tr>\n",
       "\t<tr><th scope=row>ElSalvador</th><td>60</td><td>13</td><td>13</td></tr>\n",
       "\t<tr><th scope=row>Guatemala</th><td>55</td><td> 9</td><td> 4</td></tr>\n",
       "\t<tr><th scope=row>Haiti</th><td>35</td><td> 3</td><td> 0</td></tr>\n",
       "\t<tr><th scope=row>Honduras</th><td>51</td><td> 7</td><td> 7</td></tr>\n",
       "\t<tr><th scope=row>Jamaica</th><td>87</td><td>23</td><td>21</td></tr>\n",
       "\t<tr><th scope=row>Mexico</th><td>83</td><td> 4</td><td> 9</td></tr>\n",
       "\t<tr><th scope=row>Nicaragua</th><td>68</td><td> 0</td><td> 7</td></tr>\n",
       "\t<tr><th scope=row>Panama</th><td>84</td><td>19</td><td>22</td></tr>\n",
       "\t<tr><th scope=row>Paraguay</th><td>74</td><td> 3</td><td> 6</td></tr>\n",
       "\t<tr><th scope=row>Peru</th><td>73</td><td> 0</td><td> 2</td></tr>\n",
       "\t<tr><th scope=row>TrinidadTobago</th><td>84</td><td>15</td><td>29</td></tr>\n",
       "\t<tr><th scope=row>Venezuela</th><td>91</td><td> 7</td><td>11</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 20 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & setting & effort & change\\\\\n",
       "  & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\tBolivia & 46 &  0 &  1\\\\\n",
       "\tBrazil & 74 &  0 & 10\\\\\n",
       "\tChile & 89 & 16 & 29\\\\\n",
       "\tColombia & 77 & 16 & 25\\\\\n",
       "\tCostaRica & 84 & 21 & 29\\\\\n",
       "\tCuba & 89 & 15 & 40\\\\\n",
       "\tDominicanRep & 68 & 14 & 21\\\\\n",
       "\tEcuador & 70 &  6 &  0\\\\\n",
       "\tElSalvador & 60 & 13 & 13\\\\\n",
       "\tGuatemala & 55 &  9 &  4\\\\\n",
       "\tHaiti & 35 &  3 &  0\\\\\n",
       "\tHonduras & 51 &  7 &  7\\\\\n",
       "\tJamaica & 87 & 23 & 21\\\\\n",
       "\tMexico & 83 &  4 &  9\\\\\n",
       "\tNicaragua & 68 &  0 &  7\\\\\n",
       "\tPanama & 84 & 19 & 22\\\\\n",
       "\tParaguay & 74 &  3 &  6\\\\\n",
       "\tPeru & 73 &  0 &  2\\\\\n",
       "\tTrinidadTobago & 84 & 15 & 29\\\\\n",
       "\tVenezuela & 91 &  7 & 11\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 20 × 3\n",
       "\n",
       "| <!--/--> | setting &lt;int&gt; | effort &lt;int&gt; | change &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| Bolivia | 46 |  0 |  1 |\n",
       "| Brazil | 74 |  0 | 10 |\n",
       "| Chile | 89 | 16 | 29 |\n",
       "| Colombia | 77 | 16 | 25 |\n",
       "| CostaRica | 84 | 21 | 29 |\n",
       "| Cuba | 89 | 15 | 40 |\n",
       "| DominicanRep | 68 | 14 | 21 |\n",
       "| Ecuador | 70 |  6 |  0 |\n",
       "| ElSalvador | 60 | 13 | 13 |\n",
       "| Guatemala | 55 |  9 |  4 |\n",
       "| Haiti | 35 |  3 |  0 |\n",
       "| Honduras | 51 |  7 |  7 |\n",
       "| Jamaica | 87 | 23 | 21 |\n",
       "| Mexico | 83 |  4 |  9 |\n",
       "| Nicaragua | 68 |  0 |  7 |\n",
       "| Panama | 84 | 19 | 22 |\n",
       "| Paraguay | 74 |  3 |  6 |\n",
       "| Peru | 73 |  0 |  2 |\n",
       "| TrinidadTobago | 84 | 15 | 29 |\n",
       "| Venezuela | 91 |  7 | 11 |\n",
       "\n"
      ],
      "text/plain": [
       "               setting effort change\n",
       "Bolivia        46       0      1    \n",
       "Brazil         74       0     10    \n",
       "Chile          89      16     29    \n",
       "Colombia       77      16     25    \n",
       "CostaRica      84      21     29    \n",
       "Cuba           89      15     40    \n",
       "DominicanRep   68      14     21    \n",
       "Ecuador        70       6      0    \n",
       "ElSalvador     60      13     13    \n",
       "Guatemala      55       9      4    \n",
       "Haiti          35       3      0    \n",
       "Honduras       51       7      7    \n",
       "Jamaica        87      23     21    \n",
       "Mexico         83       4      9    \n",
       "Nicaragua      68       0      7    \n",
       "Panama         84      19     22    \n",
       "Paraguay       74       3      6    \n",
       "Peru           73       0      2    \n",
       "TrinidadTobago 84      15     29    \n",
       "Venezuela      91       7     11    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read.table(\n",
    "  \"http://data.princeton.edu/wws509/datasets/effort.dat\"\n",
    "  ) -> fpe \n",
    "\n",
    "fpe # This command asks R to show us what fpe contains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a97fc0-b3f2-4caf-8a58-7fc7723ea0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[1mRows: \u001b[1m\u001b[22m\u001b[34m\u001b[34m8\u001b[34m\u001b[39m \u001b[1m\u001b[1mColumns: \u001b[1m\u001b[22m\u001b[34m\u001b[34m6\u001b[34m\u001b[39m\n",
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (1): prgtype\n",
      "\u001b[32mdbl\u001b[39m (5): gender, id, ses, schtyp, level\n",
      "\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use \u001b[30m\u001b[47m\u001b[30m\u001b[47m`spec()`\u001b[47m\u001b[30m\u001b[49m\u001b[39m to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set \u001b[30m\u001b[47m\u001b[30m\u001b[47m`show_col_types = FALSE`\u001b[47m\u001b[30m\u001b[49m\u001b[39m to quiet this message.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more files read from the web\n",
    "\n",
    "read.table(\n",
    "  \"https://stats.idre.ucla.edu/stat/data/test.txt\",\n",
    "  header = TRUE\n",
    "  ) -> test.txt \n",
    "\n",
    "read_csv(\n",
    "  \"https://stats.idre.ucla.edu/stat/data/test.csv\"\n",
    "  ) -> test.csv\n",
    "\n",
    "read_sav(\n",
    "  \"https://stats.idre.ucla.edu/stat/data/hsb2.sav\"\n",
    "  ) -> hsb2.spss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051509",
   "metadata": {},
   "source": [
    "If you look at `fpe` you will notice that there are three columns but the rows each have a unique name. These are `row names` that are remembered by R but will not show up with a column name.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ebbaf-acbb-480d-87a2-17ddb73a7e49",
   "metadata": {},
   "source": [
    "We can also ask R to both download and unzip a `*.zip` file from the web. Here I am pulling down a file from a collection maintained and updated by the Centers for Disease Control and Prevention (CDC). The file has more than `4 million` rows of data and 14 columns of information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdac5403",
   "metadata": {
    "eval": false,
    "name": "gzip"
   },
   "outputs": [],
   "source": [
    "temp = tempfile()\n",
    "\n",
    "download.file(\"ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Datasets/NVSS/bridgepop/2016/pcen_v2016_y1016.sas7bdat.zip\", temp)\n",
    "\n",
    "oursasdata = haven::read_sas(unz(temp, \"pcen_v2016_y1016.sas7bdat\"))\n",
    "\n",
    "unlink(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed1da0-c32c-4d67-b7de-ed06216e9c41",
   "metadata": {},
   "source": [
    "Now we will see three new commands -- `dim(filename)`, `head(filename)`, and `tail(filename)`. \n",
    "\n",
    "> `dim(filename)` shows the number of rows and number of columns in the dataset -- i.e., the dimensions of the dataset.\n",
    "\n",
    "> `head(filename)` show the first 6 rows and all columns while `tail(filename)` shows the last 6 rows and all columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0fcce2-1460-4519-bfeb-51d474ad297f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>4323392</li><li>14</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4323392\n",
       "\\item 14\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4323392\n",
       "2. 14\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4323392      14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(oursasdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3dd1a9-30a7-4c34-b8c3-107c3b0f8509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>age</th><th scope=col>hisp</th><th scope=col>RACESEX</th><th scope=col>VINTAGE</th><th scope=col>POP2010_apr</th><th scope=col>POP2010_jul</th><th scope=col>POP2011</th><th scope=col>POP2012</th><th scope=col>POP2013</th><th scope=col>POP2014</th><th scope=col>POP2015</th><th scope=col>POP2016</th><th scope=col>ST_FIPS</th><th scope=col>CO_FIPS</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>1</td><td>1</td><td>2016</td><td>236</td><td>242</td><td>237</td><td>229</td><td>224</td><td>240</td><td>236</td><td>225</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>2016</td><td>299</td><td>284</td><td>241</td><td>254</td><td>231</td><td>249</td><td>238</td><td>230</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>2</td><td>1</td><td>1</td><td>2016</td><td>287</td><td>292</td><td>294</td><td>233</td><td>240</td><td>237</td><td>234</td><td>255</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>3</td><td>1</td><td>1</td><td>2016</td><td>286</td><td>286</td><td>310</td><td>283</td><td>241</td><td>244</td><td>229</td><td>240</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>4</td><td>1</td><td>1</td><td>2016</td><td>270</td><td>273</td><td>280</td><td>319</td><td>278</td><td>247</td><td>252</td><td>239</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>5</td><td>1</td><td>1</td><td>2016</td><td>279</td><td>277</td><td>285</td><td>279</td><td>305</td><td>287</td><td>265</td><td>254</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 14\n",
       "\\begin{tabular}{llllllllllllll}\n",
       " age & hisp & RACESEX & VINTAGE & POP2010\\_apr & POP2010\\_jul & POP2011 & POP2012 & POP2013 & POP2014 & POP2015 & POP2016 & ST\\_FIPS & CO\\_FIPS\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 1 & 1 & 2016 & 236 & 242 & 237 & 229 & 224 & 240 & 236 & 225 & 1 & 1\\\\\n",
       "\t 1 & 1 & 1 & 2016 & 299 & 284 & 241 & 254 & 231 & 249 & 238 & 230 & 1 & 1\\\\\n",
       "\t 2 & 1 & 1 & 2016 & 287 & 292 & 294 & 233 & 240 & 237 & 234 & 255 & 1 & 1\\\\\n",
       "\t 3 & 1 & 1 & 2016 & 286 & 286 & 310 & 283 & 241 & 244 & 229 & 240 & 1 & 1\\\\\n",
       "\t 4 & 1 & 1 & 2016 & 270 & 273 & 280 & 319 & 278 & 247 & 252 & 239 & 1 & 1\\\\\n",
       "\t 5 & 1 & 1 & 2016 & 279 & 277 & 285 & 279 & 305 & 287 & 265 & 254 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 14\n",
       "\n",
       "| age &lt;dbl&gt; | hisp &lt;dbl&gt; | RACESEX &lt;dbl&gt; | VINTAGE &lt;dbl&gt; | POP2010_apr &lt;dbl&gt; | POP2010_jul &lt;dbl&gt; | POP2011 &lt;dbl&gt; | POP2012 &lt;dbl&gt; | POP2013 &lt;dbl&gt; | POP2014 &lt;dbl&gt; | POP2015 &lt;dbl&gt; | POP2016 &lt;dbl&gt; | ST_FIPS &lt;dbl&gt; | CO_FIPS &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0 | 1 | 1 | 2016 | 236 | 242 | 237 | 229 | 224 | 240 | 236 | 225 | 1 | 1 |\n",
       "| 1 | 1 | 1 | 2016 | 299 | 284 | 241 | 254 | 231 | 249 | 238 | 230 | 1 | 1 |\n",
       "| 2 | 1 | 1 | 2016 | 287 | 292 | 294 | 233 | 240 | 237 | 234 | 255 | 1 | 1 |\n",
       "| 3 | 1 | 1 | 2016 | 286 | 286 | 310 | 283 | 241 | 244 | 229 | 240 | 1 | 1 |\n",
       "| 4 | 1 | 1 | 2016 | 270 | 273 | 280 | 319 | 278 | 247 | 252 | 239 | 1 | 1 |\n",
       "| 5 | 1 | 1 | 2016 | 279 | 277 | 285 | 279 | 305 | 287 | 265 | 254 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  age hisp RACESEX VINTAGE POP2010_apr POP2010_jul POP2011 POP2012 POP2013\n",
       "1 0   1    1       2016    236         242         237     229     224    \n",
       "2 1   1    1       2016    299         284         241     254     231    \n",
       "3 2   1    1       2016    287         292         294     233     240    \n",
       "4 3   1    1       2016    286         286         310     283     241    \n",
       "5 4   1    1       2016    270         273         280     319     278    \n",
       "6 5   1    1       2016    279         277         285     279     305    \n",
       "  POP2014 POP2015 POP2016 ST_FIPS CO_FIPS\n",
       "1 240     236     225     1       1      \n",
       "2 249     238     230     1       1      \n",
       "3 237     234     255     1       1      \n",
       "4 244     229     240     1       1      \n",
       "5 247     252     239     1       1      \n",
       "6 287     265     254     1       1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(oursasdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd3e8e5d-b96b-4ac9-ab33-c32cc2ea120e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>age</th><th scope=col>hisp</th><th scope=col>RACESEX</th><th scope=col>VINTAGE</th><th scope=col>POP2010_apr</th><th scope=col>POP2010_jul</th><th scope=col>POP2011</th><th scope=col>POP2012</th><th scope=col>POP2013</th><th scope=col>POP2014</th><th scope=col>POP2015</th><th scope=col>POP2016</th><th scope=col>ST_FIPS</th><th scope=col>CO_FIPS</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>80</td><td>2</td><td>8</td><td>2016</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>56</td><td>45</td></tr>\n",
       "\t<tr><td>81</td><td>2</td><td>8</td><td>2016</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>56</td><td>45</td></tr>\n",
       "\t<tr><td>82</td><td>2</td><td>8</td><td>2016</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>56</td><td>45</td></tr>\n",
       "\t<tr><td>83</td><td>2</td><td>8</td><td>2016</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>56</td><td>45</td></tr>\n",
       "\t<tr><td>84</td><td>2</td><td>8</td><td>2016</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>56</td><td>45</td></tr>\n",
       "\t<tr><td>85</td><td>2</td><td>8</td><td>2016</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>56</td><td>45</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 14\n",
       "\\begin{tabular}{llllllllllllll}\n",
       " age & hisp & RACESEX & VINTAGE & POP2010\\_apr & POP2010\\_jul & POP2011 & POP2012 & POP2013 & POP2014 & POP2015 & POP2016 & ST\\_FIPS & CO\\_FIPS\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 80 & 2 & 8 & 2016 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 56 & 45\\\\\n",
       "\t 81 & 2 & 8 & 2016 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 56 & 45\\\\\n",
       "\t 82 & 2 & 8 & 2016 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 56 & 45\\\\\n",
       "\t 83 & 2 & 8 & 2016 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 56 & 45\\\\\n",
       "\t 84 & 2 & 8 & 2016 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 56 & 45\\\\\n",
       "\t 85 & 2 & 8 & 2016 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 56 & 45\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 14\n",
       "\n",
       "| age &lt;dbl&gt; | hisp &lt;dbl&gt; | RACESEX &lt;dbl&gt; | VINTAGE &lt;dbl&gt; | POP2010_apr &lt;dbl&gt; | POP2010_jul &lt;dbl&gt; | POP2011 &lt;dbl&gt; | POP2012 &lt;dbl&gt; | POP2013 &lt;dbl&gt; | POP2014 &lt;dbl&gt; | POP2015 &lt;dbl&gt; | POP2016 &lt;dbl&gt; | ST_FIPS &lt;dbl&gt; | CO_FIPS &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 80 | 2 | 8 | 2016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 45 |\n",
       "| 81 | 2 | 8 | 2016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 45 |\n",
       "| 82 | 2 | 8 | 2016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 45 |\n",
       "| 83 | 2 | 8 | 2016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 45 |\n",
       "| 84 | 2 | 8 | 2016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 45 |\n",
       "| 85 | 2 | 8 | 2016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 56 | 45 |\n",
       "\n"
      ],
      "text/plain": [
       "  age hisp RACESEX VINTAGE POP2010_apr POP2010_jul POP2011 POP2012 POP2013\n",
       "1 80  2    8       2016    0           0           0       0       0      \n",
       "2 81  2    8       2016    0           0           0       0       0      \n",
       "3 82  2    8       2016    0           0           0       0       0      \n",
       "4 83  2    8       2016    0           0           0       0       0      \n",
       "5 84  2    8       2016    0           0           0       0       0      \n",
       "6 85  2    8       2016    0           0           0       0       0      \n",
       "  POP2014 POP2015 POP2016 ST_FIPS CO_FIPS\n",
       "1 0       0       0       56      45     \n",
       "2 0       0       0       56      45     \n",
       "3 0       0       0       56      45     \n",
       "4 0       0       0       56      45     \n",
       "5 0       0       0       56      45     \n",
       "6 0       0       0       56      45     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(oursasdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459d80e-990c-4b8c-8f98-6718ab855e2b",
   "metadata": {},
   "source": [
    "## Labeling data values\n",
    "\n",
    "Often the data contain columns that record information with numeric codes that reflect some qualitative attributes. For example, whether an individual is Male or Female may be stored as 0 and 1, respectively. We can append the correct qualitative labels to these columns, and then hen we create graphs or tables, what is being displayed will be readily apparent (i.e., the reader\\viewer does not have to work hard to figure out what is a `0` and what is a `1`).\n",
    "\n",
    "We will read in a small dataset that has information on 200 students. The data come from the [High School and Beyond study](https://nces.ed.gov/surveys/hsb/)\n",
    "\n",
    "\n",
    "| Column Name | Values and Labels\\Meanings |\n",
    "| :-- | :-- |\n",
    "| female | (0/1) |\n",
    "| race | (1=hispanic 2=asian 3=african-amer 4=white) |\n",
    "| ses | socioeconomic status (1=low 2=middle 3=high) |\n",
    "| schtyp | type of school (1=public 2=private) |\n",
    "| prog | type of program (1=general 2=academic 3=vocational) |\n",
    "| read | standardized reading score |\n",
    "| write | standardized writing score |\n",
    "| math | standardized math score |\n",
    "| science | standardized science score |\n",
    "| socst | standardized social studies score |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b9c0a",
   "metadata": {},
   "source": [
    "# Saving R data files\n",
    "You can save your data in a format that R will recognize, giving it the **RData** or **rdata** extension "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c712c25",
   "metadata": {},
   "source": [
    "Check the **data** directory to confirm that both files are present \n",
    "\n",
    "# Minimal example of data processing\n",
    "Working with the **hsb2** data: 200 students from the [High School and Beyond study](https://nces.ed.gov/surveys/hsb/). The variables in this file are:  \n",
    "\n",
    "- female  = (0/1) \n",
    "- race = (1=hispanic 2=asian 3=african-amer 4=white) \n",
    "- ses  = socioeconomic status (1=low 2=middle 3=high) \n",
    "- schtyp =  type of school (1=public 2=private) \n",
    "- prog   = type of program (1=general 2=academic 3=vocational) \n",
    "- read  =  standardized reading score \n",
    "- write  = standardized writing score \n",
    "- math   = standardized math score \n",
    "- science = standardized science score \n",
    "- socst = standardized social studies score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222a5a7-2056-4226-8869-1fc565ed9db8",
   "metadata": {},
   "source": [
    "We can easily check the basic descriptive statistics of each column in a data file by running the `summary(filename)` command. Let us see what results if we do this with the `hsb2` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e48c964-5cf7-46c3-be96-23e003fcb19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id             female           race           ses            schtyp    \n",
       " Min.   :  1.00   Min.   :0.000   Min.   :1.00   Min.   :1.000   Min.   :1.00  \n",
       " 1st Qu.: 50.75   1st Qu.:0.000   1st Qu.:3.00   1st Qu.:2.000   1st Qu.:1.00  \n",
       " Median :100.50   Median :1.000   Median :4.00   Median :2.000   Median :1.00  \n",
       " Mean   :100.50   Mean   :0.545   Mean   :3.43   Mean   :2.055   Mean   :1.16  \n",
       " 3rd Qu.:150.25   3rd Qu.:1.000   3rd Qu.:4.00   3rd Qu.:3.000   3rd Qu.:1.00  \n",
       " Max.   :200.00   Max.   :1.000   Max.   :4.00   Max.   :3.000   Max.   :2.00  \n",
       "      prog            read           write            math      \n",
       " Min.   :1.000   Min.   :28.00   Min.   :31.00   Min.   :33.00  \n",
       " 1st Qu.:2.000   1st Qu.:44.00   1st Qu.:45.75   1st Qu.:45.00  \n",
       " Median :2.000   Median :50.00   Median :54.00   Median :52.00  \n",
       " Mean   :2.025   Mean   :52.23   Mean   :52.77   Mean   :52.65  \n",
       " 3rd Qu.:2.250   3rd Qu.:60.00   3rd Qu.:60.00   3rd Qu.:59.00  \n",
       " Max.   :3.000   Max.   :76.00   Max.   :67.00   Max.   :75.00  \n",
       "    science          socst      \n",
       " Min.   :26.00   Min.   :26.00  \n",
       " 1st Qu.:44.00   1st Qu.:46.00  \n",
       " Median :53.00   Median :52.00  \n",
       " Mean   :51.85   Mean   :52.41  \n",
       " 3rd Qu.:58.00   3rd Qu.:61.00  \n",
       " Max.   :74.00   Max.   :71.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979633d-bc06-4f44-b9e3-e7e3b573e081",
   "metadata": {},
   "source": [
    "Look at the output! R mistakenly treats several of the qualitative variables as if they are numeric, rendering incorrect information. Let us fix this problem and then we can rerun the `summary()` command to see if things have improved.\n",
    "\n",
    "The way we append value labels is by converting a numeric variable\\column to what R calls a `factor`. When we do so, we tell R to assign a particular label _(the word or the phrase)_ to a particular level _(the number)_ as shown below. \n",
    "\n",
    "> It is good habit to create a new variable each time you do some conversion so that the original variable does not get overwritten. If you do not get into the habit and end up overwriting the original variable, you will have to start from scratch if you end up making a mistake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e3e04c0-d937-48b9-97c6-a18fa5375fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor(hsb2$female,\n",
    "       levels = c(0, 1),\n",
    "       labels = c(\"Male\", \"Female\")\n",
    "       ) -> hsb2$female.f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b1d6448-4df0-41d0-8cbb-62907d2dd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the result with summary(hsb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94357c71-cddc-4e72-b46b-892b616c4674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id             female           race           ses            schtyp    \n",
       " Min.   :  1.00   Min.   :0.000   Min.   :1.00   Min.   :1.000   Min.   :1.00  \n",
       " 1st Qu.: 50.75   1st Qu.:0.000   1st Qu.:3.00   1st Qu.:2.000   1st Qu.:1.00  \n",
       " Median :100.50   Median :1.000   Median :4.00   Median :2.000   Median :1.00  \n",
       " Mean   :100.50   Mean   :0.545   Mean   :3.43   Mean   :2.055   Mean   :1.16  \n",
       " 3rd Qu.:150.25   3rd Qu.:1.000   3rd Qu.:4.00   3rd Qu.:3.000   3rd Qu.:1.00  \n",
       " Max.   :200.00   Max.   :1.000   Max.   :4.00   Max.   :3.000   Max.   :2.00  \n",
       "      prog            read           write            math      \n",
       " Min.   :1.000   Min.   :28.00   Min.   :31.00   Min.   :33.00  \n",
       " 1st Qu.:2.000   1st Qu.:44.00   1st Qu.:45.75   1st Qu.:45.00  \n",
       " Median :2.000   Median :50.00   Median :54.00   Median :52.00  \n",
       " Mean   :2.025   Mean   :52.23   Mean   :52.77   Mean   :52.65  \n",
       " 3rd Qu.:2.250   3rd Qu.:60.00   3rd Qu.:60.00   3rd Qu.:59.00  \n",
       " Max.   :3.000   Max.   :76.00   Max.   :67.00   Max.   :75.00  \n",
       "    science          socst         female.f  \n",
       " Min.   :26.00   Min.   :26.00   Male  : 91  \n",
       " 1st Qu.:44.00   1st Qu.:46.00   Female:109  \n",
       " Median :53.00   Median :52.00               \n",
       " Mean   :51.85   Mean   :52.41               \n",
       " 3rd Qu.:58.00   3rd Qu.:61.00               \n",
       " Max.   :74.00   Max.   :71.00               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9bc0a-9862-4c82-a06f-aab2636697be",
   "metadata": {},
   "source": [
    "Excellent! our variable `female.f` shows the proper labels, so let us go ahead and add labels to the remaining qualitative variables as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2659a5",
   "metadata": {},
   "source": [
    "and the `summary()` command will give you some summary information about each variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf95ff",
   "metadata": {},
   "source": [
    "There are no value labels for the various qualitative/categorical variables (female, race, ses, schtyp, and prog) but these are easily created as shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c2a4b",
   "metadata": {},
   "source": [
    "Aha! Everything is as it should be. \n",
    "\n",
    "Before we move on though, let us save our hsb2 data file that has new columns. We will save it in the native `R` format. The command to save a file is very simple -- `save(filename, file = \"filepath/filename.RData\")`\n",
    "\n",
    "> You could also do `save(filename, file = \"filepath/filename.rdata\")` if that is what you intuitively prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef874998-8451-434d-b944-1396ba414a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(hsb2, file = \"data/hsb2.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0d3d1-a934-4d54-bfaa-b912f0519797",
   "metadata": {},
   "source": [
    "## Loading RData files\n",
    "\n",
    "When we want to work with RData files, we have to load them with the `load(\"filepath/filename.RData)` command. Here I am doing it for the hsb2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94d36432-6bff-4ff3-a1ff-5b6203f4743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"data/hsb2.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "667988b5-416b-4c88-a525-774b82f02cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id             female           race           ses            schtyp    \n",
       " Min.   :  1.00   Min.   :0.000   Min.   :1.00   Min.   :1.000   Min.   :1.00  \n",
       " 1st Qu.: 50.75   1st Qu.:0.000   1st Qu.:3.00   1st Qu.:2.000   1st Qu.:1.00  \n",
       " Median :100.50   Median :1.000   Median :4.00   Median :2.000   Median :1.00  \n",
       " Mean   :100.50   Mean   :0.545   Mean   :3.43   Mean   :2.055   Mean   :1.16  \n",
       " 3rd Qu.:150.25   3rd Qu.:1.000   3rd Qu.:4.00   3rd Qu.:3.000   3rd Qu.:1.00  \n",
       " Max.   :200.00   Max.   :1.000   Max.   :4.00   Max.   :3.000   Max.   :2.00  \n",
       "      prog            read           write            math      \n",
       " Min.   :1.000   Min.   :28.00   Min.   :31.00   Min.   :33.00  \n",
       " 1st Qu.:2.000   1st Qu.:44.00   1st Qu.:45.75   1st Qu.:45.00  \n",
       " Median :2.000   Median :50.00   Median :54.00   Median :52.00  \n",
       " Mean   :2.025   Mean   :52.23   Mean   :52.77   Mean   :52.65  \n",
       " 3rd Qu.:2.250   3rd Qu.:60.00   3rd Qu.:60.00   3rd Qu.:59.00  \n",
       " Max.   :3.000   Max.   :76.00   Max.   :67.00   Max.   :75.00  \n",
       "    science          socst         female.f                race.f   \n",
       " Min.   :26.00   Min.   :26.00   Male  : 91   Hispanic        : 24  \n",
       " 1st Qu.:44.00   1st Qu.:46.00   Female:109   Asian           : 11  \n",
       " Median :53.00   Median :52.00                African American: 20  \n",
       " Mean   :51.85   Mean   :52.41                White           :145  \n",
       " 3rd Qu.:58.00   3rd Qu.:61.00                                      \n",
       " Max.   :74.00   Max.   :71.00                                      \n",
       "    ses.f       schtyp.f          prog.f   \n",
       " Low   :47   Public :168   General   : 45  \n",
       " Middle:95   Private: 32   Academic  :105  \n",
       " High  :58                 Vocational: 50  \n",
       "                                           \n",
       "                                           \n",
       "                                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a46ca1",
   "metadata": {},
   "source": [
    "## Data in packages \n",
    "Almost all R packages come bundled with data-sets, too many of them to walk you through but\n",
    "\n",
    "- [see here for standard ones](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html) \n",
    "- [here are some more](https://vincentarelbundock.github.io/Rdatasets/datasets.html) \n",
    "- [and some more](http://www.public.iastate.edu/~hofmann/data_in_r_sortable.html) \n",
    "\n",
    "To load data from a package, if you know the data-set's name, it is easy to load it, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b1eda6c-cb08-4587-b5d1-35b8f078dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>species</th><th scope=col>island</th><th scope=col>bill_length_mm</th><th scope=col>bill_depth_mm</th><th scope=col>flipper_length_mm</th><th scope=col>body_mass_g</th><th scope=col>sex</th><th scope=col>year</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Adelie</td><td>Torgersen</td><td>39.1</td><td>18.7</td><td>181</td><td>3750</td><td>male  </td><td>2007</td></tr>\n",
       "\t<tr><td>Adelie</td><td>Torgersen</td><td>39.5</td><td>17.4</td><td>186</td><td>3800</td><td>female</td><td>2007</td></tr>\n",
       "\t<tr><td>Adelie</td><td>Torgersen</td><td>40.3</td><td>18.0</td><td>195</td><td>3250</td><td>female</td><td>2007</td></tr>\n",
       "\t<tr><td>Adelie</td><td>Torgersen</td><td>  NA</td><td>  NA</td><td> NA</td><td>  NA</td><td>NA    </td><td>2007</td></tr>\n",
       "\t<tr><td>Adelie</td><td>Torgersen</td><td>36.7</td><td>19.3</td><td>193</td><td>3450</td><td>female</td><td>2007</td></tr>\n",
       "\t<tr><td>Adelie</td><td>Torgersen</td><td>39.3</td><td>20.6</td><td>190</td><td>3650</td><td>male  </td><td>2007</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 8\n",
       "\\begin{tabular}{llllllll}\n",
       " species & island & bill\\_length\\_mm & bill\\_depth\\_mm & flipper\\_length\\_mm & body\\_mass\\_g & sex & year\\\\\n",
       " <fct> & <fct> & <dbl> & <dbl> & <int> & <int> & <fct> & <int>\\\\\n",
       "\\hline\n",
       "\t Adelie & Torgersen & 39.1 & 18.7 & 181 & 3750 & male   & 2007\\\\\n",
       "\t Adelie & Torgersen & 39.5 & 17.4 & 186 & 3800 & female & 2007\\\\\n",
       "\t Adelie & Torgersen & 40.3 & 18.0 & 195 & 3250 & female & 2007\\\\\n",
       "\t Adelie & Torgersen &   NA &   NA &  NA &   NA & NA     & 2007\\\\\n",
       "\t Adelie & Torgersen & 36.7 & 19.3 & 193 & 3450 & female & 2007\\\\\n",
       "\t Adelie & Torgersen & 39.3 & 20.6 & 190 & 3650 & male   & 2007\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 8\n",
       "\n",
       "| species &lt;fct&gt; | island &lt;fct&gt; | bill_length_mm &lt;dbl&gt; | bill_depth_mm &lt;dbl&gt; | flipper_length_mm &lt;int&gt; | body_mass_g &lt;int&gt; | sex &lt;fct&gt; | year &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Adelie | Torgersen | 39.1 | 18.7 | 181 | 3750 | male   | 2007 |\n",
       "| Adelie | Torgersen | 39.5 | 17.4 | 186 | 3800 | female | 2007 |\n",
       "| Adelie | Torgersen | 40.3 | 18.0 | 195 | 3250 | female | 2007 |\n",
       "| Adelie | Torgersen |   NA |   NA |  NA |   NA | NA     | 2007 |\n",
       "| Adelie | Torgersen | 36.7 | 19.3 | 193 | 3450 | female | 2007 |\n",
       "| Adelie | Torgersen | 39.3 | 20.6 | 190 | 3650 | male   | 2007 |\n",
       "\n"
      ],
      "text/plain": [
       "  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n",
       "1 Adelie  Torgersen 39.1           18.7          181               3750       \n",
       "2 Adelie  Torgersen 39.5           17.4          186               3800       \n",
       "3 Adelie  Torgersen 40.3           18.0          195               3250       \n",
       "4 Adelie  Torgersen   NA             NA           NA                 NA       \n",
       "5 Adelie  Torgersen 36.7           19.3          193               3450       \n",
       "6 Adelie  Torgersen 39.3           20.6          190               3650       \n",
       "  sex    year\n",
       "1 male   2007\n",
       "2 female 2007\n",
       "3 female 2007\n",
       "4 NA     2007\n",
       "5 female 2007\n",
       "6 male   2007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(palmerpenguins)\n",
    "\n",
    "data(penguins, package = 'palmerpenguins')\n",
    "\n",
    "head(penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "952501a5-d078-4c5c-8c85-6c2a78b9e090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>carat</th><th scope=col>cut</th><th scope=col>color</th><th scope=col>clarity</th><th scope=col>depth</th><th scope=col>table</th><th scope=col>price</th><th scope=col>x</th><th scope=col>y</th><th scope=col>z</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.23</td><td>Ideal    </td><td>E</td><td>SI2 </td><td>61.5</td><td>55</td><td>326</td><td>3.95</td><td>3.98</td><td>2.43</td></tr>\n",
       "\t<tr><td>0.21</td><td>Premium  </td><td>E</td><td>SI1 </td><td>59.8</td><td>61</td><td>326</td><td>3.89</td><td>3.84</td><td>2.31</td></tr>\n",
       "\t<tr><td>0.23</td><td>Good     </td><td>E</td><td>VS1 </td><td>56.9</td><td>65</td><td>327</td><td>4.05</td><td>4.07</td><td>2.31</td></tr>\n",
       "\t<tr><td>0.29</td><td>Premium  </td><td>I</td><td>VS2 </td><td>62.4</td><td>58</td><td>334</td><td>4.20</td><td>4.23</td><td>2.63</td></tr>\n",
       "\t<tr><td>0.31</td><td>Good     </td><td>J</td><td>SI2 </td><td>63.3</td><td>58</td><td>335</td><td>4.34</td><td>4.35</td><td>2.75</td></tr>\n",
       "\t<tr><td>0.24</td><td>Very Good</td><td>J</td><td>VVS2</td><td>62.8</td><td>57</td><td>336</td><td>3.94</td><td>3.96</td><td>2.48</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 10\n",
       "\\begin{tabular}{llllllllll}\n",
       " carat & cut & color & clarity & depth & table & price & x & y & z\\\\\n",
       " <dbl> & <ord> & <ord> & <ord> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0.23 & Ideal     & E & SI2  & 61.5 & 55 & 326 & 3.95 & 3.98 & 2.43\\\\\n",
       "\t 0.21 & Premium   & E & SI1  & 59.8 & 61 & 326 & 3.89 & 3.84 & 2.31\\\\\n",
       "\t 0.23 & Good      & E & VS1  & 56.9 & 65 & 327 & 4.05 & 4.07 & 2.31\\\\\n",
       "\t 0.29 & Premium   & I & VS2  & 62.4 & 58 & 334 & 4.20 & 4.23 & 2.63\\\\\n",
       "\t 0.31 & Good      & J & SI2  & 63.3 & 58 & 335 & 4.34 & 4.35 & 2.75\\\\\n",
       "\t 0.24 & Very Good & J & VVS2 & 62.8 & 57 & 336 & 3.94 & 3.96 & 2.48\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 10\n",
       "\n",
       "| carat &lt;dbl&gt; | cut &lt;ord&gt; | color &lt;ord&gt; | clarity &lt;ord&gt; | depth &lt;dbl&gt; | table &lt;dbl&gt; | price &lt;int&gt; | x &lt;dbl&gt; | y &lt;dbl&gt; | z &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.23 | Ideal     | E | SI2  | 61.5 | 55 | 326 | 3.95 | 3.98 | 2.43 |\n",
       "| 0.21 | Premium   | E | SI1  | 59.8 | 61 | 326 | 3.89 | 3.84 | 2.31 |\n",
       "| 0.23 | Good      | E | VS1  | 56.9 | 65 | 327 | 4.05 | 4.07 | 2.31 |\n",
       "| 0.29 | Premium   | I | VS2  | 62.4 | 58 | 334 | 4.20 | 4.23 | 2.63 |\n",
       "| 0.31 | Good      | J | SI2  | 63.3 | 58 | 335 | 4.34 | 4.35 | 2.75 |\n",
       "| 0.24 | Very Good | J | VVS2 | 62.8 | 57 | 336 | 3.94 | 3.96 | 2.48 |\n",
       "\n"
      ],
      "text/plain": [
       "  carat cut       color clarity depth table price x    y    z   \n",
       "1 0.23  Ideal     E     SI2     61.5  55    326   3.95 3.98 2.43\n",
       "2 0.21  Premium   E     SI1     59.8  61    326   3.89 3.84 2.31\n",
       "3 0.23  Good      E     VS1     56.9  65    327   4.05 4.07 2.31\n",
       "4 0.29  Premium   I     VS2     62.4  58    334   4.20 4.23 2.63\n",
       "5 0.31  Good      J     SI2     63.3  58    335   4.34 4.35 2.75\n",
       "6 0.24  Very Good J     VVS2    62.8  57    336   3.94 3.96 2.48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "data(diamonds, package = 'ggplot2')\n",
    "\n",
    "head(diamonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5c37",
   "metadata": {},
   "source": [
    "---------------\n",
    "## Exercises for practice \n",
    "These are some exercises you can use to practice and build your R skills. They are not for grade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534085f0",
   "metadata": {},
   "source": [
    "#### Exercise 01: Reading in some data files \n",
    "\n",
    "1. Create a new Notebook by going to File -> New -> Notebook.\n",
    "\n",
    "2. When prompted to select a kernel, use the dropdown menu to select the _R_ kernel. \n",
    "\n",
    "3. The notebook will be untitled, so go ahead and save it with a name, something like `yourlastname_ex01` and you will see `yourlastname_ex01.ipynb` as the name. \n",
    "\n",
    "4. Now read in the `Stata` data file found [here](http://www.stata.com/data/jwooldridge/eacsap/mroz.dta) \n",
    "\n",
    "5. Create a new cell and run the `summary` command to check the contents of this data file and look at the first 6 rows of data with the appropriate `head` command.and look at the first 6 rows of data with the appropriate `head` command.\n",
    "\n",
    "6. In a new cell, read in tthe `SPSS` file found [here](http://calcnet.mth.cmich.edu/org/spss/V16_materials/DataSets_v16/airline_passengers.sav) \n",
    "\n",
    "7. In a new cell, run the `summary` command and look at the first 6 rows of data with the appropriate `head` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355b38e-aa1b-4c66-9eb5-96aa9489977c",
   "metadata": {},
   "source": [
    "#### Exercise 02: Reading in local data and labeling some values\n",
    "\n",
    "1. Download [this dataset](https://s3.amazonaws.com/tripdata/201502-citibike-tripdata.zip), extract the file inside the zip archive and upload it to the `data` folder. \n",
    "\n",
    "2. In a new cell, read in this uploaded data file with the appropriate commands. \n",
    "\n",
    "3. The variable `gender` has the following codes: `Zero = unknown; 1 = male; 2 = female`.  Use this coding scheme to create a new column that shows `gender` as a `factor` with these value labels \n",
    "\n",
    "4. Check the first 6 rows of the dataset and also run `summary` to check the new column was created as desired. \n",
    "\n",
    "5. In a new cell, write the commands necessary to save each of the three data-sets as separate `RData` files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b1ed5",
   "metadata": {},
   "source": [
    "#### Exercise 03: Welcome to Kaggle & Mass Shootings \n",
    "\n",
    "Go to [this page on Kaggle](https://www.kaggle.com/zusmani/us-mass-shootings-last-50-years) and read the description of the data-set on mass shootings in the United States that occurred during the 1966-2017 period. once you have read the overview of the data, click the \"Data\" tab and download the file called `Mass Shootings Dataset.csv`. Be careful; there are several versions so the one you want is the very last one and not any that have a version number attached, such as \"Mass Shootings Dataset Ver 2.csv\" for example. \n",
    "\n",
    "Now read this file, perhaps naming it `shootings` and run the `summary()` command on it. Note the number of observations and the number of variables in the data-set. \n",
    "\n",
    "Make sure you save the file in RData format as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f633aea",
   "metadata": {},
   "source": [
    "#### Exercise 04: Animal Shelters \n",
    "\n",
    "Go to [this page on Kaggle](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-outcomes-and) and download the file called `aac_shelter_outcomes.zip`, unzip it, and AFTER reading the data overview, read in the file and generate the usual `summary` and also save it as an RData file."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "name,eval,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
