{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffbd9b83-8717-470b-ab2c-62fe824c712e",
   "metadata": {},
   "source": [
    "# MPA 5830 - Module 04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d07d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## {lubridate} \n",
    "Working with dates and times is not as simple as it looks, and the reasons are as many as they are diverse. Let us spell out a few of the major ones. \n",
    "\n",
    "For one, dates come in all shapes and sizes, as text that looks like this: \"Monday, Jan10, 2010\" to strings like \"2020-28-01 12:49\" but no matter what software you use, you have to be able to convert all dates into a standard format.  \n",
    "\n",
    "Second, if you need to calculate how much time has passed between events, for example, how many days go by before a patient returns to the Emergency Room (ER), how many days between Covid-19 deaths in an infected population, hours needed to fly from Columbus to an Francisco, and so on ... you need to be able to move between months, days, hours, etc with ease, AND calculate the length of time in a way that automatically adjusts for `leap` years. \n",
    "\n",
    "There are many more reasons I could advance but we might as well start working with dates. First up, some mangled date entries and we'll see how to parse them into correct date formats! We will rely on the `lubridate` package to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17994647",
   "metadata": {
    "name": "lu01"
   },
   "outputs": [],
   "source": [
    "\"20171217\" -> today1 \n",
    "\"2017-12-17\" -> today2 \n",
    "\"2017 December 17\" -> today3 \n",
    "\"20171217143241\" -> today4 \n",
    "\"2017 December 17 14:32:41\" -> today5 \n",
    "\"December 17 2017 14:32:41\" -> today6 \n",
    "\"17-Dec, 2017 14:32:41\" -> today7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3a6eb",
   "metadata": {},
   "source": [
    "Now we fix them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69756ee3-f0b3-4f80-9ccd-f22de297aa5d",
   "metadata": {
    "name": "lu02"
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(lubridate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe2178-dbcd-4d7d-ad85-cbb2a457bfd3",
   "metadata": {
    "name": "lu02"
   },
   "outputs": [],
   "source": [
    "ymd(today1) -> date1\n",
    "ymd(today2) -> date2 \n",
    "ymd(today3) -> date3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8338ee-386f-4fde-a4d1-90c073bf5b18",
   "metadata": {
    "name": "lu02"
   },
   "outputs": [],
   "source": [
    "date1; date2; date3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe320fa7",
   "metadata": {},
   "source": [
    "`today1`, `today2`, and `today3` all had the same structure of year-month-day and so `ymd()` works to get the format right. \n",
    "\n",
    "`today4` has year-month-day-hours-minutes-seconds so we'll have to do this one slightly differently. The same thing works for `today5` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3948c-76e3-4110-b433-9d71e1950d6c",
   "metadata": {
    "name": "lu03"
   },
   "outputs": [],
   "source": [
    "ymd_hms(today4) -> date4 \n",
    "ymd_hms(today5) -> date5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f716c-138f-40a1-ac5a-b468c8f7288f",
   "metadata": {
    "name": "lu03"
   },
   "outputs": [],
   "source": [
    "date4; date5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c8982",
   "metadata": {},
   "source": [
    "`today6` has a slightly different format, `month-day-year-hours-minutes-seconds` that is read in thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd692f-d80c-4744-a3f5-eafb7903d240",
   "metadata": {
    "name": "lu04"
   },
   "outputs": [],
   "source": [
    "mdy_hms(today6) -> date6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b7f51-ab68-40cb-aae8-2196b7edc24b",
   "metadata": {
    "name": "lu04"
   },
   "outputs": [],
   "source": [
    "date6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b817d465",
   "metadata": {},
   "source": [
    "`today7` has a slightly different format, `day-month-year-hours-minutes-seconds` that is read in thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf17849-c227-437c-af08-4d2cdc8e1128",
   "metadata": {
    "name": "lu05"
   },
   "outputs": [],
   "source": [
    "dmy_hms(today7) -> date7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2133b41-5e5d-4090-9e15-ccdbad9a64d1",
   "metadata": {
    "name": "lu05"
   },
   "outputs": [],
   "source": [
    "date7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4860b-d9e3-41bb-88e8-80bf53ddaec1",
   "metadata": {},
   "source": [
    "Notice how regardless of the format pf the raw data, merely invoking the correct sequence of ymd, mdy, dmy, etc flips the raw date into properly formatted date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f96655c",
   "metadata": {},
   "source": [
    "## Working with flight dates\n",
    "Now we should be able to start working with some date variables, and the ideal candidate would be the flight date column in our `cmhflights` data. So the first thing we will do is load that data-set so that we can work with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ed1c7",
   "metadata": {
    "name": "lu06"
   },
   "outputs": [],
   "source": [
    "load(\"data/cmhflights_01092017.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a4758-90e1-4d0a-99de-c6baea079ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(cmhflights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff90860",
   "metadata": {},
   "source": [
    "I dislike the uppercase-lowercase mixture they have in their column names and so will get rid of it as shown below, making everything nice and lowercase. This is done with the `janitor` package's `clean_names()` command. \n",
    "\n",
    "I am also going to use `select()` to keep only a handful of columns since keeping 100+ is of no value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db42f1e-137d-4bfe-9bca-5a26c477bf3a",
   "metadata": {
    "name": "lu07"
   },
   "outputs": [],
   "source": [
    "library(janitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec33b4-bd87-42be-9fbb-e9b8b50c93d1",
   "metadata": {
    "name": "lu07"
   },
   "outputs": [],
   "source": [
    "cmhflights %>%\n",
    "  clean_names() %>%\n",
    "  select(\n",
    "    year, month, dayof_month, day_of_week, flight_date, carrier,\n",
    "    tail_num, flight_num, origin_city_name, dest_city_name,\n",
    "    dep_time, dep_delay, arr_time, arr_delay, cancelled, diverted\n",
    "    ) -> cmh.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5f42f",
   "metadata": {},
   "source": [
    "The first thing I want to do now is to label the days of the week, the months, and then also create a flag for the `weekend` versus `weekdays`. Here goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48e4c7",
   "metadata": {
    "name": "lu08"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  mutate(\n",
    "    dayofweek = wday(\n",
    "      day_of_week,\n",
    "      abbr = FALSE,\n",
    "      label = TRUE\n",
    "      ),\n",
    "    monthname = month(\n",
    "      month,\n",
    "      abbr = FALSE,\n",
    "      label = TRUE\n",
    "      ),\n",
    "    weekend = case_when(\n",
    "      dayofweek %in% c(\"Saturday\", \"Sunday\") ~ \"Weekend\",\n",
    "      TRUE ~ \"Weekday\"\n",
    "      )\n",
    "    ) -> cmh.df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa0881",
   "metadata": {},
   "source": [
    "#### Now let us ask some questions:  \n",
    "    (a) What month had the most flights?  \n",
    "    (b) What day of the week had the most flights?  \n",
    "    (c) What about weekends; did weekends have more flights than weekdays?  \n",
    "    (d) With respect to (c), does whatever pattern we see vary by month, or does month not matter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d37e7-3ae7-420b-a160-104c3d3c374e",
   "metadata": {
    "name": "lu09"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  count(monthname, sort = TRUE) # (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335dfba-87a9-46b4-81f3-5c99b74efdd9",
   "metadata": {
    "name": "lu09"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  count(dayofweek, sort = TRUE) # (b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f66dc5-31ec-4898-9484-324f8bb7e53b",
   "metadata": {
    "name": "lu09"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  count(weekend, sort = TRUE) # (c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f40a6b-c4af-4e1e-bd2b-93a579b52d2d",
   "metadata": {
    "name": "lu09"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  count(monthname, weekend, sort = TRUE) # (d) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc3e52",
   "metadata": {},
   "source": [
    "So most flights are on weekdays, but weekend flights lead in July while weekday flights lead in August. \n",
    "\n",
    "But wait a minute, if I can calculate these frequencies, why not do it by the hour. That may allow us to answer such questions as: What hour of the day has the most flights, the most delays? What about by airline? What if we push this to the minute of the hour? \n",
    "\n",
    "Well, first we will have to create a new variable that marks just the hour of the day in the 24-hour cycle. But to do this we will first need to create a single `flight_date_time` column that will be in the `ymd_hms` format. How? With `unite()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4b2d7",
   "metadata": {
    "name": "lu10"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  unite(\n",
    "    col = \"flight_date_time\",\n",
    "    c(flight_date, dep_time),\n",
    "    sep = \":\",\n",
    "    remove = FALSE\n",
    "  ) -> cmh.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549fd53",
   "metadata": {},
   "source": [
    "Okay, now we create `flt_date_time` and note the seconds here are automatically coerced to be `00` because the raw date field not not include the seconds, only hour and minutes. But a proper date field must include seconds for accurate calculations and hence seconds are set to `00` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47a83f",
   "metadata": {
    "name": "lu11"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  mutate(\n",
    "    flt_date_time = ymd_hm(flight_date_time)\n",
    "      ) -> cmh.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9cdb3-1dcb-4536-abcc-48c50116e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(cmh.df$flt_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cb137",
   "metadata": {},
   "source": [
    "The warning indicates there are 471 flight dates that could not be parsed correctly.\n",
    "\n",
    "Now we extract just the hour of the day the flight was scheduled to depart, with `hour()` and `minute()`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4062766",
   "metadata": {
    "name": "lu12"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  mutate(\n",
    "    flt_hour = hour(flt_date_time),\n",
    "    flt_minute = minute(flt_date_time)\n",
    "    ) -> cmh.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745841bf",
   "metadata": {},
   "source": [
    "All righty then, now we start digging in. What hour has the most flights, and does this vary by the day of the week? By the Month? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7624638-8d8d-4b99-86b3-66ac69f4d6ed",
   "metadata": {
    "name": "lu13"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  count(flt_hour, sort = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d81f52-fa9a-496d-9c28-2db9e1ecb11a",
   "metadata": {
    "name": "lu13"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  count(monthname, flt_hour, sort = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5e80c",
   "metadata": {},
   "source": [
    "Looks like 10:00 and then 17:00, these would be your best bets if you were looking to catch a flight and wanted as many options as possible. On the flip side, this might also be the time when flights get delayed more often because there are so many flights scheduled at these hours! \n",
    "\n",
    "Now I want to ask the question about delays: Are median delays higher at certain hours?Notice the results are being arranged first in descending and then in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a5cc4-7f43-4a20-8f19-95cb192084d8",
   "metadata": {
    "name": "lu14"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  group_by(flt_hour) %>%\n",
    "  summarise(md.delay = median(dep_delay, na.rm = TRUE)) %>%\n",
    "  arrange(-md.delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bec19-82a8-4a11-87bb-187d8277a35a",
   "metadata": {
    "name": "lu14"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  group_by(flt_hour) %>%\n",
    "  summarise(md.delay = median(dep_delay, na.rm = TRUE)) %>%\n",
    "  arrange(md.delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96364654",
   "metadata": {},
   "source": [
    "The expected result -- shortest median delay is at 5 AM, and delays increase by the hour. \n",
    "\n",
    "__Bottom-line:__ Fly as early as you can. Might this vary by destination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a1b9e",
   "metadata": {
    "name": "lu15"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  group_by(dest_city_name, flt_hour) %>%\n",
    "  summarise(md.delay = median(dep_delay, na.rm = TRUE)) %>%\n",
    "  arrange(-md.delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e24af",
   "metadata": {},
   "source": [
    "Avoid flying to Newark, NJ, even at 6 or 7 AM. \n",
    "\n",
    "Might these vary by airline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff5ac9",
   "metadata": {
    "name": "lu16"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  group_by(carrier, dest_city_name, flt_hour) %>%\n",
    "  summarise(md.delay = median(dep_delay, na.rm = TRUE)) %>%\n",
    "  arrange(-md.delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1acae",
   "metadata": {},
   "source": [
    "Worst early-morning delays are for EV, to Newark and to Chicago. \n",
    "\n",
    "## Passage of Time\n",
    "Let us assume we are interested in seeing how much time lapses between successive flights of **each aircraft** seen in the data. We know we can identify each unique aircraft by its `tail_num`. So let us first see how many times is each aircraft seen and create a new column called `number_flew`. \n",
    "\n",
    "Some rows of data are missing `flt_date_time` and `tail_num` so I will filter these out as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ba942-2d44-4074-8342-30cb72b981ac",
   "metadata": {
    "name": "lu17"
   },
   "outputs": [],
   "source": [
    "cmh.df %>%\n",
    "  filter( # eliminates all rows where both these columns are blank \n",
    "    !is.na(tail_num),\n",
    "    !is.na(flt_date_time) \n",
    "    ) %>% \n",
    "  group_by(tail_num) %>% \n",
    "  arrange(flt_date_time) %>% # each aircraft is now stacked by when it flew\n",
    "  mutate(n_flew = row_number()) %>% # each time aan aircraft is seen it gets a number, 1, 2, 3, and so on ... \n",
    "  select(tail_num, flt_date_time, n_flew) %>%\n",
    "  arrange(-n_flew) -> cmh.df2 # N396SW is seen the most often in this data-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59528ef9-eb73-4f50-ad10-8364c41851e9",
   "metadata": {
    "name": "lu17"
   },
   "outputs": [],
   "source": [
    "cmh.df2 %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027a5f-ef0c-4827-8217-3499e71a899c",
   "metadata": {},
   "source": [
    "So far so good; [N396SW is the winner and has well-earned its retirement](https://www.planespotters.net/airframe/boeing-737-n396sw-aerothrust-holdings/38l2ge). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7afaa-dd0b-44e8-a37a-24fa3c5d9fb2",
   "metadata": {},
   "source": [
    "Now we need to see how much time lapsed between flights, and this is just the difference between the **preceding** `flt_date_time` recorded and the **most recent** `flt_date_time`. As we do this, note that by default time span (`ytspan`) is calculated in seconds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699653fd-be72-4df9-8153-04b5e9752129",
   "metadata": {
    "name": "lu18"
   },
   "outputs": [],
   "source": [
    "cmh.df2 %>%\n",
    "  group_by(tail_num) %>%\n",
    "  arrange(flt_date_time) %>%\n",
    "  mutate(\n",
    "    tspan = interval(\n",
    "      lag(flt_date_time, order_by = tail_num), flt_date_time\n",
    "      ), # calculate the time span between successive flights recorded and save as new varable tspan\n",
    "    tspan.minutes = as.duration(tspan)/dminutes(1), # convert tspan into minutes and save as tspan.minutes\n",
    "    tspan.hours = as.duration(tspan)/dhours(1), # convert tspan into hours and save as tspan.hours\n",
    "    tspan.days = as.duration(tspan)/ddays(1), # convert tspan into days and save as tspan.days \n",
    "    tspan.weeks = as.duration(tspan)/dweeks(1) # convert tspan into weeks and save as tspan.weeks \n",
    "    ) -> cmh.df2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a87d5",
   "metadata": {},
   "source": [
    "Here, `tspan` is being converted into, say, minutes by dividing it by 60, into hours by dividing tspan by 60 x 60 = 3600, and so on. \n",
    "\n",
    "Note that `dminutes(1)` is calculating the time span in one-minute intervals. Similarly for hours, days, and weeks. Thus if you ran `dhours(2)` you would get the time interval in 2-hour increments.  \n",
    "\n",
    "There is a lot more we could do with time but the few things we have covered so far would be the more common tasks we usually encounter.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e04e3a-bbe5-48fc-9285-7fadfc333573",
   "metadata": {},
   "source": [
    "Before we move on, let us see the flight sequence of **N396SW** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0faa6ea-4e1d-490b-9ba0-99bc6e6c645d",
   "metadata": {
    "name": "lu18"
   },
   "outputs": [],
   "source": [
    "cmh.df2 %>%\n",
    "    filter(tail_num == \"N396SW\") %>%\n",
    "    head(., 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d4249-416f-4305-a6ef-62cbbfd45b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmh.df2 %>%\n",
    "    filter(tail_num == \"N396SW\") %>%\n",
    "    tail(., 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b9fb2-9a99-4cb8-a85d-869310438389",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb720c6-db9c-4239-a82c-d4f87ed7b31b",
   "metadata": {},
   "source": [
    "# Exercises for Practice\n",
    "\n",
    "## Exercise 01 \n",
    "\n",
    "The data below come from [tidytuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-09-10) and provide information on accidents at theme parks. You can see more of these [data available here](https://ridesdatabase.org/saferparks/data/). The data give you some details of where and when the accident occurred, and something about the injured party as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f06d27",
   "metadata": {
    "name": "ex01"
   },
   "outputs": [],
   "source": [
    "library(readr)\n",
    "\n",
    "read_csv(\n",
    "    \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-10/saferparks.csv\"\n",
    "    ) -> safer_parks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fa488-a3bd-4ac4-8863-e46bc19d3799",
   "metadata": {},
   "source": [
    "|variable             |class     |description |\n",
    "|:--------------------|:---------|:-----------|\n",
    "|acc_id               |double    | Unique ID |\n",
    "|acc_date             |character | Accident Date |\n",
    "|acc_state            |character | Accident State |\n",
    "|acc_city             |character | Accident City |\n",
    "|fix_port             |character |.           |\n",
    "|source               |character | Source of injury report |\n",
    "|bus_type             |character | Business type |\n",
    "|industry_sector      |character | Industry sector |\n",
    "|device_category      |character | Device category |\n",
    "|device_type          |character | Device type |\n",
    "|tradename_or_generic |character | Common name of the device |\n",
    "|manufacturer         |character | Manufacturer of device |\n",
    "|num_injured          |double    | Num injured |\n",
    "|age_youngest         |double    | Youngest individual injured |\n",
    "|gender               |character | Gender of individual injured |\n",
    "|acc_desc             |character | Description of accident |\n",
    "|injury_desc          |character | Injury description |\n",
    "|report               |character | Report URL |\n",
    "|category             |character | Category of accident |\n",
    "|mechanical           |double    | Mechanical failure (binary NA/1) |\n",
    "|op_error             |double    | Operator error (binary NA/1)|\n",
    "|employee             |double    | Employee error (binary NA/1)|\n",
    "|notes                |character | Additional notes| \n",
    "\n",
    "Working with the `safer_parks` data, complete the following tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfd58c-e6ac-47ab-9dcc-937c49814005",
   "metadata": {},
   "source": [
    "### Problem (a)\n",
    "Using `acc_date`, create a new date variable called `idate` that is a proper date column generated via ``{lubridate}``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c63df0",
   "metadata": {},
   "source": [
    "### Problem (b)\n",
    "Now create new columns for (i) the month of the accident, and (ii) the day of the week. These should not be abbreviated (i.e., we should see the values as 'Monday' instead of 'Mon', \"July\" instead of \"Jul\"). \n",
    "\n",
    "What month had the highest number of accidents? \n",
    "\n",
    "What day of the week had the highest number of accidents? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbff08",
   "metadata": {},
   "source": [
    "### Problem (c)\n",
    "What if you look at days of the week by month? Does the same day of the week show up with the most accidents regardless of month or do we see some variation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de36ad",
   "metadata": {},
   "source": [
    "### Problem (d)\n",
    "What were the `five` dates with the most number of accidents? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c1eb5",
   "metadata": {},
   "source": [
    "### Problem (e)\n",
    "Using the Texas injury data, answer the following question: What ride was the safest? [Hint: For each ride (`ride_name`) you will need to calculate the number of days between accidents. The ride with the highest number of days is the safest.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547c716",
   "metadata": {
    "name": "txinjury"
   },
   "outputs": [],
   "source": [
    "read_csv(\n",
    "  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-10/tx_injuries.csv\"\n",
    "  ) -> tx_injuries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cd5a8",
   "metadata": {},
   "source": [
    "\n",
    "|variable          |class     |description |\n",
    "|:-----------------|:---------|:-----------|\n",
    "|injury_report_rec |double    | Unique Record ID |\n",
    "|name_of_operation |character | Company name |\n",
    "|city              |character | City |\n",
    "|st                |character | State (all TX) |\n",
    "|injury_date       |character | Injury date - note there are some different formats |\n",
    "|ride_name         |character | Ride Name |\n",
    "|serial_no         |character | Serial number of ride |\n",
    "|gender            |character | Gender of the injured individual |\n",
    "|age               |character | Age of the injured individual |\n",
    "|body_part         |character | Body part injured |\n",
    "|alleged_injury    |character | Alleged injury - type of injury |\n",
    "|cause_of_injury   |character | Approximate cause of the injury (free text) |\n",
    "|other             |character | Anecdotal information in addition to cause of injury |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f465c",
   "metadata": {},
   "source": [
    "You should note that this assumes each ride was in operation for the same amount of time. If this is not true then our estimates will be unreliable. \n",
    "\n",
    "## Exercise 02\n",
    "These data (see below) come from this story: [The next generation: The space race is dominated by new contenders](https://www.economist.com/graphic-detail/2018/10/18/the-space-race-is-dominated-by-new-contenders). You have data on space missions over time, with dates of the launch, the launching agency/country, type of launch vehicle, and so on. \n",
    "\n",
    "\n",
    "| variable    | definition                               |\n",
    "| ----------- | ---------------------------------------- |\n",
    "| tag         | Harvard or [COSPAR][cospar] id of launch |\n",
    "| JD          | [Julian Date][jd] of launch              |\n",
    "| launch_date | date of launch                           |\n",
    "| launch_year | year of launch                           |\n",
    "| type        | type of launch vehicle                   |\n",
    "| variant     | variant of launch vehicle                |\n",
    "| mission     | space mission                            |\n",
    "| agency      | launching agency                         |\n",
    "| state_code  | launching agency's state                 |\n",
    "| category    | success (O) or failure (F)               |\n",
    "| agency_type | type of agency                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv(\n",
    "  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv\"\n",
    "  ) -> launches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394a673",
   "metadata": {},
   "source": [
    "### Problem (a) \n",
    "Create a new column called `date` that stores `launch_date` as a proper data field in ymd format from `{lubridate}`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21a977",
   "metadata": {},
   "source": [
    "### Problem (b) \n",
    "Creating columns as needed, calculate and show the number of launches first by year, then by month, and then by day of the week. The result should be arranged in descending order of the number of launches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e9ff7",
   "metadata": {},
   "source": [
    "### Problem (c) \n",
    "How many launches were successful `(O)` versus failed `(F)` by country and year? \n",
    "\n",
    "Note: The countries of interest will be state_code values of \"CN\", \"F\", \"J\", \"RU\", \"SU\", \"US\". In addition, you do not need to arrange your results in any order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ba46e-352c-489f-afa4-436b8c21f9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "include,name,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
