{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6920149b-f37b-48c2-9a4f-dd4e2fbdc7b3",
   "metadata": {},
   "source": [
    "# MPA 5830 - Module 01 (Fall 2021)\n",
    "\n",
    "#### What will you learn?\n",
    "In this module you will learn how to \n",
    "\n",
    "(a) access data files in R, both locally (i.e., from a folder on your computer) and from the web (i.e., without manually downloading a data file);\n",
    "\n",
    "(b) explore the contents of a data file with specific comands, \n",
    "\n",
    "(c) add value labels and create a new qualitative variable, \n",
    "\n",
    "(d) save data files in native R format, \n",
    "\n",
    "(e) load RData files, and\n",
    "\n",
    "(f) create, populate, and save a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eca76a-d664-4fa4-a5fe-0c1ebc8afde1",
   "metadata": {},
   "source": [
    "Base R comes bundled with some built-in functions (pieces of computer code) that do a variety of things. But one often needs additional pieces of computer code to accomplish a task. Often, base R could dprobably have done the task but we might be able to complete the task faster\\easier by relying on these additional pieces of computer code. You will see these additioal pieces of code being used time to time, and we call these little bundles of code __packages__.\n",
    "\n",
    "We start by loading up a package -- [tidyverse](https://www.tidyverse.org/) -- \"an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\" \n",
    "\n",
    "Well, what exactly is a __package__ in the R language? A package is best thought of as a collection of R functions, data, and documentation that explains what each function does. R has over 14,000 packages, each designed to do something very specific such as, for example, make maps, read large data files very speedily, make animated graphics, and so on. \n",
    "\n",
    "Each week you will see several new packages come into play because we will be relying on each to do something very specific for us. The __tidyverse__ will be a regular feature. \n",
    "\n",
    "How do we load a package? Well, first it has to be installed, but that has been taken care of for you. Once installed, we load it via the `library(packaganame)` command, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34598b",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "\n",
    "body{ /* Normal  */\n",
    "/*      font-family: Lato, sans-serif;  \n",
    "      font-family: Mukta, sans-serif; \n",
    "      font-family: 'Nunito Sans', sans-serif;\n",
    "      font-family: Karla, sans-serif;  */\n",
    "      font-family: 'Merriweather Sans', sans-serif; \n",
    "      font-size: 18px;\n",
    "  }\n",
    "\n",
    "h1.title {\n",
    "  font-size: 38px;\n",
    "  color: DarkRed;\n",
    "}\n",
    "h1 { /* Header 1 */\n",
    "  font-size: 28px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "h2 { /* Header 2 */\n",
    "    font-size: 22px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "h3 { /* Header 3 */\n",
    "  font-size: 18px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "code.r{ /* Code block */\n",
    "    font-family: Mukta, sans-serif; \n",
    "    font-weight: 600;\n",
    "    font-size: 16px;\n",
    "}\n",
    "/* pre { /* Code block - determines code spacing between lines */\n",
    "    font-size: 16px;\n",
    "} */\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c47f41",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c68ab-a1c6-4616-a2b3-40bc07ea7ae1",
   "metadata": {},
   "source": [
    "The message you see with a pinkish background results from our `library(tidyverse)` command, and is just a message indicating what packages were loaded (`ggplot2, tibble, tidyr, readr, purr, dplyr, stringr, forcats`), and if there is anything else we should be aware of. In this case, there is -- some commands (`filter()` and `lag()`) used by the `dplyr` package conflict with identically named commands in the `stats` package. \n",
    "\n",
    "`readr` is an excellent package designed to read data that might be available in various formats. Since it is loaded as a part of the `tidyverse`, let us move on to seeing how to read data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07b901",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "One of the golden rules to follow when reading data is to make your life easy by not having to memorize or discover through frantic trial-and-error runs where a particular data file is located. So how do we make our life easy? By placing all __data__ in a data folder. \n",
    "\n",
    "\n",
    "Data come in several formats but I will walk you through the formats you are most likely to encounter -- MS Excel, CSV, TXT, fixed-width, and then in any one of these commercial software formats: SAS, Stata, or SPSS. \n",
    "\n",
    "### CSV data files \n",
    "We start by reading a simple `comma-separated variable` format file and then a `tab-delimited variable` format file. A CSV file has each column separated by a `comma` while a tab-delimited file has every column separated by a `tab` -- `,` versus `\\t` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3297ca-d00a-4449-9117-daf3ad0ff36d",
   "metadata": {
    "eval": true,
    "name": "csvtab"
   },
   "outputs": [],
   "source": [
    "read.csv(\n",
    "    \"data/ImportDataCSV.csv\",\n",
    "    sep = \",\",\n",
    "    header = TRUE\n",
    "    ) -> df.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e835341-47cb-4c0c-8cbb-94b4c5444561",
   "metadata": {},
   "outputs": [],
   "source": [
    "read.csv(\n",
    "  \"data/ImportDataTAB.txt\",\n",
    "  sep = \"\\t\",\n",
    "  header = TRUE\n",
    "  ) -> df.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1513fb",
   "metadata": {},
   "source": [
    "Note ... \n",
    "* \"data/ImportDataCSV.csv\" specifies the specific file that should be read from the data folder.  \n",
    "* The `sep = \",\"` switch says the individual variables are separated by a comma \n",
    "* `header = TRUE` switch indicates that the first row in the file that is being read in has the column names  \n",
    "* The tab-delimited file needs `sep = \"\\t\"` because the columns are separated by a tab \n",
    "\n",
    "If no errors are thrown, then the files should have been read into memory and we can check their contents. The `names(filename)` command will show you the column names, and `glimpse(filename)` will show you a snippet of the data in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89329079-18cd-41ac-8069-9d5368db3ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names(df.csv) \n",
    "\n",
    "glimpse(df.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b443792-89d2-43e2-a0c4-8e17f6a93316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we repeat the preceding commands for the df.tab file\n",
    "\n",
    "names(df.tab)\n",
    "\n",
    "glimpse(df.tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d3061",
   "metadata": {},
   "source": [
    "## MS Excel files\n",
    "\n",
    "Microsoft **Excel** files can be read via the `readxl` package, and you see two versions below -- one for the older `*.xls` format and the other for the newer `*.xlsx` format. \n",
    "\n",
    "As a rule, I would recommend against storing data in Excel formats since Excel tends to do some funny things. If you must store and share data, try to use the CSV format.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429261ec",
   "metadata": {
    "eval": true,
    "name": "excel"
   },
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "\n",
    "read_excel(\n",
    "  \"data/ImportDataXLS.xls\"\n",
    "  ) -> df.xls \n",
    "\n",
    "read_excel(\n",
    "  \"data/ImportDataXLSX.xlsx\"\n",
    "  ) -> df.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9e9e1-b025-4996-beb3-919a440bcde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(df.xls)\n",
    "\n",
    "glimpse(df.xls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892258d-76b1-4e23-8932-5451d85923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(df.xlsx)\n",
    "\n",
    "glimpse(df.xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f52871",
   "metadata": {},
   "source": [
    "## SPSS, Stata, SAS files\n",
    "Some governmental agencies and other sources tend to use SAS, Stata, or SPSS for storing data and for carrying out various data analyses. This is a legacy issue that is changing but a little too slowly for most of us who do not use these commercial software packages as the mainstays of our data work. But, even if you do not use these packages, you should know how to read in data created in their native formats. As it turns out, **SPSS, Stata, SAS** files can be read via the `haven` package, and with relative ease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af7ab3",
   "metadata": {
    "eval": true,
    "name": "others"
   },
   "outputs": [],
   "source": [
    "library(haven)\n",
    "\n",
    "read_stata(\n",
    "  \"data/ImportDataStata.dta\"\n",
    "  ) -> df.stata\n",
    "\n",
    "read_sas(\n",
    "  \"data/ImportDataSAS.sas7bdat\"\n",
    "  ) -> df.sas\n",
    "\n",
    "read_sav(\n",
    "  \"data/ImportDataSPSS.sav\"\n",
    "  ) -> df.spss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a087c6-d798-472e-bba1-a149e45bfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the files\n",
    "\n",
    "names(df.stata)\n",
    "\n",
    "glimpse(df.sas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebafbd41",
   "metadata": {},
   "source": [
    "## Fixed-width files \n",
    "It is also common to encounter **fixed-width** files where the raw data are stored without any gaps between successive columns. This is also a legacy format from the early days of computers and punch cards, and one of the most efficient ways of storing large amounts of data. These files come with documentation that will give you the necessary details about where each column starts and ends, etc. [See here for some examples of layouts from the Census Bureau](https://www.census.gov/programs-surveys/geography/technical-documentation/records-layout/2010-zcta-record-layout.html#par_textimage_0).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7d9c5",
   "metadata": {
    "eval": true,
    "name": "dfw"
   },
   "outputs": [],
   "source": [
    "read.fwf(\n",
    "  \"data/fwfdata.txt\",\n",
    "  widths = c(4, 9, 2, 4),\n",
    "  header = FALSE,\n",
    "  col.names = c(\"Name\", \"Month\", \"Day\", \"Year\")\n",
    "  ) -> df.fw "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27104e75",
   "metadata": {},
   "source": [
    "Notice we need `widths = c(4,9,2,4)` to indicate how many slots each column takes and then `col.names = c(\"Name\", \"Month\", \"Day\", \"Year\")` to label the columns since the data file does not have variable names. if you mess up with `widths = ` you end up with garbage because R does not know where any column starts or ends so be careful.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f1e2b-30c2-4570-a63a-4c343435cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(df.fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ae283",
   "metadata": {},
   "source": [
    "# Reading Files from the Web\n",
    "One of the benefits of software like R is its ability to read data files over the web __without requiring you to manually download the file and save a physical copy to be read in__. Specifically, it is possible to list the full web-path for a file and read it in. This ability is invaluable when the data tend to be periodically updated by the source (for example, by the Census Bureau, Bureau of Labor, Bureau of Economic Analysis, etc.). Here are a few examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96942516",
   "metadata": {
    "eval": true,
    "name": "readfiles"
   },
   "outputs": [],
   "source": [
    "read.table(\n",
    "  \"http://data.princeton.edu/wws509/datasets/effort.dat\"\n",
    "  ) -> fpe \n",
    "\n",
    "fpe # This command asks R to show us what fpe contains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a97fc0-b3f2-4caf-8a58-7fc7723ea0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more files read from the web\n",
    "\n",
    "read.table(\n",
    "  \"https://stats.idre.ucla.edu/stat/data/test.txt\",\n",
    "  header = TRUE\n",
    "  ) -> test.txt \n",
    "\n",
    "read_csv(\n",
    "  \"https://stats.idre.ucla.edu/stat/data/test.csv\"\n",
    "  ) -> test.csv\n",
    "\n",
    "read_sav(\n",
    "  \"https://stats.idre.ucla.edu/stat/data/hsb2.sav\"\n",
    "  ) -> hsb2.spss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051509",
   "metadata": {},
   "source": [
    "If you look at `fpe` you will notice that there are three columns but the rows each have a unique name. These are `row names` that are remembered by R but will not show up with a column name.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ebbaf-acbb-480d-87a2-17ddb73a7e49",
   "metadata": {},
   "source": [
    "We can also ask R to both download and unzip a `*.zip` file from the web. Here I am pulling down a file from a collection maintained and updated by the Centers for Disease Control and Prevention (CDC). The file has more than `4 million` rows of data and 14 columns of information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac5403",
   "metadata": {
    "eval": false,
    "name": "gzip"
   },
   "outputs": [],
   "source": [
    "temp = tempfile()\n",
    "\n",
    "download.file(\"ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Datasets/NVSS/bridgepop/2016/pcen_v2016_y1016.sas7bdat.zip\", temp)\n",
    "\n",
    "oursasdata = haven::read_sas(unz(temp, \"pcen_v2016_y1016.sas7bdat\"))\n",
    "\n",
    "unlink(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed1da0-c32c-4d67-b7de-ed06216e9c41",
   "metadata": {},
   "source": [
    "Now we will see three new commands -- `dim(filename)`, `head(filename)`, and `tail(filename)`. \n",
    "\n",
    "> `dim(filename)` shows the number of rows and number of columns in the dataset -- i.e., the dimensions of the dataset.\n",
    "\n",
    "> `head(filename)` show the first 6 rows and all columns while `tail(filename)` shows the last 6 rows and all columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fcce2-1460-4519-bfeb-51d474ad297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(oursasdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3dd1a9-30a7-4c34-b8c3-107c3b0f8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(oursasdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e8e5d-b96b-4ac9-ab33-c32cc2ea120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(oursasdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459d80e-990c-4b8c-8f98-6718ab855e2b",
   "metadata": {},
   "source": [
    "## Labeling data values\n",
    "\n",
    "Often the data contain columns that record information with numeric codes that reflect some qualitative attributes. For example, whether an individual is Male or Female may be stored as 0 and 1, respectively. We can append the correct qualitative labels to these columns, and then hen we create graphs or tables, what is being displayed will be readily apparent (i.e., the reader\\viewer does not have to work hard to figure out what is a `0` and what is a `1`).\n",
    "\n",
    "We will read in a small dataset that has information on 200 students. The data come from the [High School and Beyond study](https://nces.ed.gov/surveys/hsb/)\n",
    "\n",
    "\n",
    "| Column Name | Values and Labels\\Meanings |\n",
    "| :-- | :-- |\n",
    "| female | (0/1) |\n",
    "| race | (1=hispanic 2=asian 3=african-amer 4=white) |\n",
    "| ses | socioeconomic status (1=low 2=middle 3=high) |\n",
    "| schtyp | type of school (1=public 2=private) |\n",
    "| prog | type of program (1=general 2=academic 3=vocational) |\n",
    "| read | standardized reading score |\n",
    "| write | standardized writing score |\n",
    "| math | standardized math score |\n",
    "| science | standardized science score |\n",
    "| socst | standardized social studies score |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b9c0a",
   "metadata": {},
   "source": [
    "# Saving R data files\n",
    "You can save your data in a format that R will recognize, giving it the **RData** or **rdata** extension "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c712c25",
   "metadata": {},
   "source": [
    "Check the **data** directory to confirm that both files are present \n",
    "\n",
    "# Minimal example of data processing\n",
    "Working with the **hsb2** data: 200 students from the [High School and Beyond study](https://nces.ed.gov/surveys/hsb/). The variables in this file are:  \n",
    "\n",
    "- female  = (0/1) \n",
    "- race = (1=hispanic 2=asian 3=african-amer 4=white) \n",
    "- ses  = socioeconomic status (1=low 2=middle 3=high) \n",
    "- schtyp =  type of school (1=public 2=private) \n",
    "- prog   = type of program (1=general 2=academic 3=vocational) \n",
    "- read  =  standardized reading score \n",
    "- write  = standardized writing score \n",
    "- math   = standardized math score \n",
    "- science = standardized science score \n",
    "- socst = standardized social studies score \n",
    "\n",
    "Let us start by reading in these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f34cd-2031-4395-82ab-349a210e7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "read.table(\n",
    "  'https://stats.idre.ucla.edu/stat/data/hsb2.csv',\n",
    "  header = TRUE,\n",
    "  sep = \",\"\n",
    "  ) -> hsb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222a5a7-2056-4226-8869-1fc565ed9db8",
   "metadata": {},
   "source": [
    "We can easily check the basic descriptive statistics of each column in a data file by running the `summary(filename)` command. Let us see what results if we do this with the `hsb2` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee103b-74fe-4c01-bacd-103970bb91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48c964-5cf7-46c3-be96-23e003fcb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979633d-bc06-4f44-b9e3-e7e3b573e081",
   "metadata": {},
   "source": [
    "Look at the output! R mistakenly treats several of the qualitative variables as if they are numeric, rendering incorrect information. Let us fix this problem and then we can rerun the `summary()` command to see if things have improved.\n",
    "\n",
    "The way we append value labels is by converting a numeric variable\\column to what R calls a `factor`. When we do so, we tell R to assign a particular label _(the word or the phrase)_ to a particular level _(the number)_ as shown below. \n",
    "\n",
    "> It is good habit to create a new variable each time you do some conversion so that the original variable does not get overwritten. If you do not get into the habit and end up overwriting the original variable, you will have to start from scratch if you end up making a mistake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef6476-3eaf-4b87-a7b9-9b80ad783b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor(hsb2$female,\n",
    "       levels = c(0, 1),\n",
    "       labels = c(\"Male\", \"Female\")\n",
    "       ) -> hsb2$female.f \n",
    "\n",
    "factor(hsb2$race,\n",
    "       levels = c(1:4),\n",
    "       labels = c(\"Hispanic\", \"Asian\", \"African American\", \"White\")\n",
    "       ) -> hsb2$race.f\n",
    "\n",
    "factor(hsb2$ses,\n",
    "       levels = c(1:3),\n",
    "       labels = c(\"Low\", \"Middle\", \"High\")\n",
    "       ) -> hsb2$ses.f\n",
    "\n",
    "factor(hsb2$schtyp,\n",
    "       levels = c(1:2),\n",
    "       labels = c(\"Public\", \"Private\")\n",
    "       ) -> hsb2$schtyp.f\n",
    "\n",
    "factor(hsb2$prog,\n",
    "       levels = c(1:3),\n",
    "       labels = c(\"General\", \"Academic\", \"Vocational\")\n",
    "       ) -> hsb2$prog.f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a407599-facc-4a9a-8ee5-1f619d68c448",
   "metadata": {},
   "source": [
    "Now we check our work by re-running the `summary(hsb2)` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015ebbb-116a-473e-8842-818d079ce28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c2a4b",
   "metadata": {},
   "source": [
    "Aha! Everything is as it should be. \n",
    "\n",
    "Before we move on though, let us save our hsb2 data file that has new columns. We will save it in the native `R` format. The command to save a file is very simple -- `save(filename, file = \"filepath/filename.RData\")`\n",
    "\n",
    "> You could also do `save(filename, file = \"filepath/filename.rdata\")` if that is what you intuitively prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef874998-8451-434d-b944-1396ba414a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(hsb2, file = \"data/hsb2.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0d3d1-a934-4d54-bfaa-b912f0519797",
   "metadata": {},
   "source": [
    "## Loading RData files\n",
    "\n",
    "When we want to work with RData files, we have to load them with the `load(\"filepath/filename.RData\")` command. Here I am doing it for the hsb2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d36432-6bff-4ff3-a1ff-5b6203f4743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"data/hsb2.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667988b5-416b-4c88-a525-774b82f02cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(hsb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a46ca1",
   "metadata": {},
   "source": [
    "## Data in packages \n",
    "Almost all R packages come bundled with data-sets, too many of them to walk you through but\n",
    "\n",
    "- [see here for standard ones](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html) \n",
    "- [here are some more](https://vincentarelbundock.github.io/Rdatasets/datasets.html) \n",
    "- [and some more](http://www.public.iastate.edu/~hofmann/data_in_r_sortable.html) \n",
    "\n",
    "To load data from a package, if you know the data-set's name, it is easy to load it, as shown below. Some times you may need to install the package. We do this with the `install.packages(\"packagename\")` command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1eda6c-cb08-4587-b5d1-35b8f078dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('palmerpenguins')\n",
    "\n",
    "library(palmerpenguins)\n",
    "\n",
    "data(penguins, package = 'palmerpenguins')\n",
    "\n",
    "head(penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952501a5-d078-4c5c-8c85-6c2a78b9e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "data(diamonds, package = 'ggplot2')\n",
    "\n",
    "head(diamonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5c37",
   "metadata": {},
   "source": [
    "---------------\n",
    "## Exercises for practice \n",
    "These are some exercises you can use to practice and build your R skills. They are not for grade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534085f0",
   "metadata": {},
   "source": [
    "#### Exercise 01: Reading in some data files \n",
    "\n",
    "1. Create a new Notebook by going to File -> New -> Notebook.\n",
    "\n",
    "2. When prompted to select a kernel, use the dropdown menu to select the _R_ kernel. \n",
    "\n",
    "3. The notebook will be untitled, so go ahead and save it with a name, something like `yourlastname_ex01` and you will see `yourlastname_ex01.ipynb` as the name. \n",
    "\n",
    "4. Now read in the `Stata` data file found [here](http://www.stata.com/data/jwooldridge/eacsap/mroz.dta) \n",
    "\n",
    "5. Create a new cell and run the `summary` command to check the contents of this data file and look at the first 6 rows of data with the appropriate `head` command.and look at the first 6 rows of data with the appropriate `head` command.\n",
    "\n",
    "6. In a new cell, read in tthe `SPSS` file found [here](http://calcnet.mth.cmich.edu/org/spss/V16_materials/DataSets_v16/airline_passengers.sav) \n",
    "\n",
    "7. In a new cell, run the `summary` command and look at the first 6 rows of data with the appropriate `head` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355b38e-aa1b-4c66-9eb5-96aa9489977c",
   "metadata": {},
   "source": [
    "#### Exercise 02: Reading in local data and labeling some values\n",
    "\n",
    "1. Download [this dataset](https://s3.amazonaws.com/tripdata/201502-citibike-tripdata.zip), extract the file inside the zip archive and upload it to the `data` folder. \n",
    "\n",
    "2. In a new cell, read in this uploaded data file with the appropriate commands. \n",
    "\n",
    "3. The variable `gender` has the following codes: `Zero = unknown; 1 = male; 2 = female`.  Use this coding scheme to create a new column that shows `gender` as a `factor` with these value labels \n",
    "\n",
    "4. Check the first 6 rows of the dataset and also run `summary` to check the new column was created as desired. \n",
    "\n",
    "5. In a new cell, write the commands necessary to save each of the three data-sets as separate `RData` files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b1ed5",
   "metadata": {},
   "source": [
    "#### Exercise 03: Welcome to Kaggle & Mass Shootings \n",
    "\n",
    "Go to [this page on Kaggle](https://www.kaggle.com/zusmani/us-mass-shootings-last-50-years) and read the description of the data-set on mass shootings in the United States that occurred during the 1966-2017 period. once you have read the overview of the data, click the \"Data\" tab and download the file called `Mass Shootings Dataset.csv`. Be careful; there are several versions so the one you want is the very last one and not any that have a version number attached, such as \"Mass Shootings Dataset Ver 2.csv\" for example. \n",
    "\n",
    "Now read this file, perhaps naming it `shootings` and run the `summary()` command on it. Note the number of observations and the number of variables in the data-set. \n",
    "\n",
    "Make sure you save the file in RData format as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f633aea",
   "metadata": {},
   "source": [
    "#### Exercise 04: Animal Shelters \n",
    "\n",
    "Go to [this page on Kaggle](https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-outcomes-and) and download the file called `aac_shelter_outcomes.zip`, unzip it, and AFTER reading the data overview, read in the file and generate the usual `summary` and also save it as an RData file."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "name,eval,tags,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
