{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6523fccf",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "\n",
    "body{ /* Normal  */\n",
    "/*    font-family: Lato, sans-serif;  \n",
    "      font-family: Mukta, sans-serif; \n",
    "      font-family: 'Nunito Sans', sans-serif;\n",
    "      font-family: Karla, sans-serif;  */\n",
    "      font-family: 'Merriweather Sans', sans-serif; \n",
    "      font-size: 18px;\n",
    "  }\n",
    "\n",
    "h1.title {\n",
    "  font-size: 38px;\n",
    "  color: DarkRed;\n",
    "}\n",
    "\n",
    "h1 { /* Header 1 */\n",
    "  font-size: 28px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "\n",
    "h2 { /* Header 2 */\n",
    "    font-size: 22px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "\n",
    "h3 { /* Header 3 */\n",
    "  font-size: 18px;\n",
    "  color: DarkBlue;\n",
    "}\n",
    "\n",
    "code.r{ /* Code block */\n",
    "    font-family: Mukta, sans-serif; \n",
    "    font-weight: 600;  \n",
    "    font-size: 16px;\n",
    "}\n",
    "\n",
    "/* pre { /* Code block - determines code spacing between lines */\n",
    "    font-size: 16px;\n",
    "} */\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b98956-974a-4faa-ad01-891ad17adc0f",
   "metadata": {
    "name": "setupn",
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "# MPA 5830 - Module 03 (Fall 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d8959",
   "metadata": {},
   "source": [
    "In the previous week we learned how to clean and prepare data with several {dplyr} functions -- `select()`, `filter()`, `summarise()`, `mutate()`, `group_by()`, `case_when()`, and so on. In this module we will tackle other challenging problems and lean on another package, `{tidyr}` to do so. \n",
    "\n",
    "# {tidyr}\n",
    "This library seems to have only four core functions, `separate`, `unite()`, `pivot_longer`, and `pivot_wider()` but each of them packs a wallop.  \n",
    "\n",
    "## separate()\n",
    "You will, at times, end up with columns that contain multiple pieces of information, all mashed up into some alphanumeric string or sequence of numbers. `separate()` allows us to split this mashed up column into specific pieces. For example, here are some data from the Census Bureau: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73a518",
   "metadata": {
    "name": "tidy01"
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "\n",
    "read_csv(\n",
    "  \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2018/metro/totals/cbsa-est2018-alldata.csv\"\n",
    "  ) -> cbsa\n",
    "\n",
    "cbsa %>%\n",
    "  select(NAME) %>%\n",
    "  glimpse()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444aae5",
   "metadata": {},
   "source": [
    "This data-set contains population estimates for CBSAs -- core-based statistical areas. What are these? \n",
    "\n",
    "> Metropolitan and Micropolitan Statistical Areas are collectively referred to as Core-Based Statistical Areas.\n",
    "> Metropolitan statistical areas have at least one urbanized area of 50,000 or more population, plus adjacent territory that has a high degree of social and economic integration with the core as measured by commuting ties.\n",
    "Micropolitan statistical areas are a new set of statistical areas that have at least one urban cluster of at least 10,000 but less than 50,000 population, plus adjacent territory that has a high degree of social and economic integration with the core as measured by commuting ties.\n",
    "> Metropolitan and micropolitan statistical areas are defined in terms of whole counties or county equivalents, including the six New England states. As of June 6, 2003, there are 362 metropolitan statistical areas and 560 micropolitan statistical areas in the United States. [Source](https://www.census.gov/topics/housing/housing-patterns/about/core-based-statistical-areas.html)\n",
    "\n",
    "Look at the column called `NAME` and note how It combines the state's name (abbreviated) and the name of the area, \"Abilene, TX\", \"Callahan County, TX\", \"Jones County, TX\", and so on. \n",
    "\n",
    "This is a common issue with many census data-sets and so it would be nice to be able to split up this `NAME` column into two pieces \n",
    "\n",
    "    (1) `placename` (\"Abilene\", \"Callahan County\", etc) and \n",
    "    (2) `stateabb` (\"TX\", \"TX\", etc.) \n",
    "    \n",
    "We do this below, with the separation occurring where a `\",\"` is seen in `NAME`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee857d4-5f79-42b2-9486-70f83c36068d",
   "metadata": {
    "name": "tidy02"
   },
   "outputs": [],
   "source": [
    "cbsa %>%\n",
    "  separate(\n",
    "    col = NAME, \n",
    "    into = c(\"placename\", \"stateabb\"),\n",
    "    sep = \", \",\n",
    "    remove = FALSE\n",
    "  ) -> cbsa "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8870e0d-85d9-439c-abb6-6163bb4da741",
   "metadata": {},
   "source": [
    "Let us see the original column and the two new columns we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27c070-e311-4c87-98e6-c8bc5c085942",
   "metadata": {
    "name": "tidy02"
   },
   "outputs": [],
   "source": [
    "cbsa %>%\n",
    "  select(NAME, placename, stateabb) %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f08efe",
   "metadata": {},
   "source": [
    "Here is what each piece of code is doing:\n",
    "\n",
    "| code     | what it does ... |\n",
    "|:--       | :----            |\n",
    "| col =    | identifies the column to be separated |\n",
    "| into =   | creates the names for the new columns that will result |\n",
    "| sep =    | indicates where the separation should occur |\n",
    "| remove = | indicates whether the column to be separated should be removed from the data-set or retained once the new columns have been created. Setting it equal to `FALSE` will keep the original column, `TRUE` will remove it. |\n",
    "\n",
    "What if the column to be separated was made up of numbers rather than text? Take the `STCOU` column, for instance. Look like numbers, right? Except these numbers are really identifiers, FIPS codes to be exact, with the first two digits flagging what state this area is in and the next three digits identifying the area itself. Ohio's FIPS code is, for instance, `39`, and Portage County's FIPS code is `133`. So here, it would be nice to create two new columns, one with the state FIPS code (`stfips`) and the second with the county FIPS code (`coufips`). We do this below, but this time setting `sep = 2` because we want the separation to happen after the second digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c26807",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "tidy03"
   },
   "outputs": [],
   "source": [
    "cbsa %>%\n",
    "  separate(\n",
    "    col = STCOU, \n",
    "    into = c(\"stfips\", \"coufips\"),\n",
    "    sep = 2,\n",
    "    remove = FALSE\n",
    "  ) -> cbsa\n",
    "\n",
    "cbsa %>%\n",
    "  select(STCOU, stfips, coufips) %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c41f1d",
   "metadata": {},
   "source": [
    "## unite()\n",
    "This is the very opposite of `separate()` -- two or more columns are united into ONE column. For example, take the file I am reading in as `coudf`. This file has similar content to what we read in for the CBSAs but this one has data for counties and states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b0f91",
   "metadata": {
    "name": "tidy04"
   },
   "outputs": [],
   "source": [
    "read_csv(\n",
    "  \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2018/counties/totals/co-est2018-alldata.csv\"\n",
    "  ) -> coudf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e73c37",
   "metadata": {},
   "source": [
    "Let us filter this file so that we retain rows only for counties. I am doing this with `filter(COUNTY != \"000\")` because the state rows are the ones with `COUNTY == \"000\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9983dfb",
   "metadata": {
    "name": "tidy05"
   },
   "outputs": [],
   "source": [
    "coudf %>%\n",
    "  filter(COUNTY != \"000\") -> coudf2\n",
    "\n",
    "coudf2 %>%\n",
    "  select(STNAME, CTYNAME) %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27a71a",
   "metadata": {},
   "source": [
    "Now I want to combine the county name (`CTYNAME`) and the state name (`STNAME`) into a single column, with the two names separated by a comma and a single white-space, i.e., by `\", \"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151ff6e",
   "metadata": {
    "name": "tidy06"
   },
   "outputs": [],
   "source": [
    "coudf2 %>%\n",
    "  unite(\n",
    "    col = \"countystate\",\n",
    "    c(\"CTYNAME\", \"STNAME\"),\n",
    "    sep = \", \",\n",
    "    remove = FALSE\n",
    "  ) -> coudf2\n",
    "\n",
    "coudf2 %>%\n",
    "  select(CTYNAME, STNAME, countystate) %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90145d49",
   "metadata": {},
   "source": [
    "Key elements here, are, \n",
    "\n",
    "| code | what it does ... |\n",
    "| :--  | :--              |\n",
    "| col = | identifies the `new column` to be created |\n",
    "| c(\"..\") | identifies the columns to be combined, as in c(\"column1\", \"column2\", \"column3\") |\n",
    "| sep = | indicates if we want the merged elements to be separated in some manner. Here we are using \", \" to separate with a comma followed by a single white-space. But we could have used any separator or no separator at all |\n",
    "| remove = | indicates if we want the original columns deleted `(TRUE)` or not `(FALSE)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d37f8e",
   "metadata": {},
   "source": [
    "## Pivoting data \n",
    "If I look at the original CBSA file `cbsa`, I see that it has been setup very oddly. In particular, starting with column 6 we have a jumble of information ...\n",
    "\n",
    "+ CENSUS2010POP, ESTIMATESBASE2010, POPESTIMATE2010 all have the population totals for 2010. \n",
    "+ POPESTIMATE2011 through POPESTIMATE2018 are the population totals for 2011-2018 \n",
    "+ NPOPCHG_20XY give us net population change for 2010-2018 \n",
    "+ BIRTHS20XY give us the number of births for 2010-2018 \n",
    "+ DEATHS20XY give us the number of deaths for 2010-2018 \n",
    "+ NATURALINC20XY gives us the natural increase = births - deaths for 2010-2018 \n",
    "+ INTERNATIONALMIG20XY gives us international immigrant totals for for 2010-2018 \n",
    "+ DOMESTICMIG20XY gives us domestic migrant totals for 2010-2018 \n",
    "+ NETMIG20XY give us net migration totals for 2010-2018 \n",
    "+ RESIDUAL20XY gives us some small numbers left over after adding and subtracting the \n",
    "\n",
    "Let us keep only a few columns (columns 4, and then 8 through 16) to see what the current layout looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f302f8",
   "metadata": {
    "name": "tidy07"
   },
   "outputs": [],
   "source": [
    "read_csv(\n",
    "  \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2018/metro/totals/cbsa-est2018-alldata.csv\"\n",
    "  ) -> cbsa\n",
    "\n",
    "cbsa %>%\n",
    "  select(c(4, 8:16)) -> cbsa01\n",
    "\n",
    "cbsa01 %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f000016",
   "metadata": {},
   "source": [
    "### Wide-to-Long with pivot_longer() \n",
    "Why did they not setup the data in such a way that it had the following `tidy` structure? This would make a lot more sense rather than having each year be a column all its own. \n",
    "\n",
    "| NAME | YEAR | POPULATION |\n",
    "| :--  | :--  | :--        |\n",
    "| Abilene, TX | 2010 | 165583 |\n",
    "| Abilene, TX | 2011 | 166616 |\n",
    "| Abilene, TX | 2012 | 167447 |\n",
    "| ....        | .... | ....   |\n",
    "| Callahan County, TX | 2010 | 13513 |\n",
    "| Callahan County, TX | 2011 | 13511 |\n",
    "| Callahan County, TX | 2012 | 13488 |\n",
    "| ....        | .... | ....   |\n",
    "\n",
    "Well, we can easily create the proper structure of the data-set, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffdb426",
   "metadata": {
    "name": "tidy08"
   },
   "outputs": [],
   "source": [
    "cbsa01 %>%\n",
    "  group_by(NAME) %>%\n",
    "  pivot_longer(\n",
    "    names_to = \"variable\",\n",
    "    values_to = \"POPULATION\",\n",
    "    cols = 2:10\n",
    "  ) -> cbsa01.long\n",
    "\n",
    "cbsa01.long %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bb8fb",
   "metadata": {},
   "source": [
    "| code | what it does ... |\n",
    "| :-- | :-- |\n",
    "| names_to = | identifies the name of the new column that will be created |\n",
    "| values_to = | identifies the name of the new column in which values will be stored |\n",
    "| cols = | identifies the columns that will be pivoted from wide to long |\n",
    "| group_by() = | holds unique combinations of whatever column names you put in `group_by()` fixed while it pivots the other columns |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697f6a8",
   "metadata": {},
   "source": [
    "I still need to clean up the variable column so that it only shows the four-digit year rather than POPESTIMATE2010, and so on. Let us do this next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1320507",
   "metadata": {
    "name": "tidy09"
   },
   "outputs": [],
   "source": [
    "cbsa01.long %>%\n",
    "  separate(\n",
    "    col = variable,\n",
    "    into = c(\"todiscard\", \"toyear\"),\n",
    "    sep = 11,\n",
    "    remove = TRUE) -> cbsa01.long2\n",
    "\n",
    "cbsa01.long2 %>%\n",
    "  mutate(YEAR = as.numeric(toyear)) %>%\n",
    "    select(c(NAME, YEAR, POPULATION)) -> cbsa01.long3\n",
    "\n",
    "cbsa01.long3 %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afe46d-7994-405b-9175-69ad2a59e9ef",
   "metadata": {},
   "source": [
    "Another way to do this would have been with the `stringr` package, something we will see a little of down the road. Here, we use a specific function (_str_remove_all_) from `stringr` to eliminate the \"POPESTIMATE\" string more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d6363-53f8-4ff4-a64a-f531c5f10702",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbsa01.long %>%\n",
    "    mutate(\n",
    "    Year = stringr::str_remove_all(variable, \"POPESTIMATE\")\n",
    "    ) -> cbsa.long4\n",
    "\n",
    "cbsa.long4 %>%\n",
    "    select(-variable) %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5f0bd",
   "metadata": {},
   "source": [
    "### Long-to-wide \n",
    "\n",
    "Now, let us say the data-set was a different one, perhaps the one shown below. This data-set comes from the 2017 American Community Survey and along with state FIPS codes (`geoid`) and state name (`NAME`) it contains data on `income` = median yearly income, `rent` = median monthly rent, and `moe` = the margin of error at the 90% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e4f57",
   "metadata": {
    "name": "tidy10"
   },
   "outputs": [],
   "source": [
    "us_rent_income %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c7ed7",
   "metadata": {},
   "source": [
    "Notice here the setup looks weird because two different variables (_income_ and _rent_) have been combined in a single column. In addition, the estimate and the moe (the margin of error) for both income and rent is also squeezed into single columns respectively. \n",
    "\n",
    "Instead, the data-set should have been `tidyly` setup as follows:\n",
    "\n",
    "| GEOID | NAME    | income | rent | moe_income | moe_rent |\n",
    "| :--   | :--     | --:    | --:  | --:        | --:      |\n",
    "| 01    | Alabama | 24476  | 747  | 136        | 3        |\n",
    "| 02    | Alaska  | 32940  | 1200 | 508        | 13       |\n",
    "| 03    | Arizona | 27517  | 972  | 148        | 4        |\n",
    "| ...   | ...     | ...    | ...  | ...        | ...      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f0213",
   "metadata": {},
   "source": [
    "Well, this can be done as well, with the `pivot_wider()` function that takes from the \"long\" format to the \"wide\" format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430292a7",
   "metadata": {
    "name": "tidy11"
   },
   "outputs": [],
   "source": [
    "us_rent_income %>%\n",
    "  group_by(GEOID, NAME) %>%\n",
    "  pivot_wider(\n",
    "    names_from = variable,\n",
    "    values_from = c(estimate, moe)\n",
    "  ) -> usri.wide\n",
    "\n",
    "usri.wide %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c77fdf",
   "metadata": {},
   "source": [
    "| code | what it does ... |\n",
    "| :-- | :-- |\n",
    "| names_from = | identifies the column from which unique values will be taken to create the names of the new columns that will result |\n",
    "| values_from = | identifies the column(s) from which the values should be assigned to the new columns that will result |\n",
    "| group_by() | holds unique value combinations of whatever column names you put in `group_by()` fixed while it pivots the rows to new columns |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a7e4f",
   "metadata": {},
   "source": [
    "### The example that follows is a tricky one so be careful!!  \n",
    "\n",
    "Here is another example, this time with the `cbsa` data but showing you how we might use a combination of `pivot_longer()` and `pivot_wider()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cde62",
   "metadata": {
    "name": "tidy12"
   },
   "outputs": [],
   "source": [
    "cbsa %>%\n",
    "  select(3:5, 8:88) %>%\n",
    "  group_by(NAME) %>%\n",
    "  pivot_longer(\n",
    "    names_to = \"variable\",\n",
    "    values_to = \"estimate\",\n",
    "    cols = 4:84\n",
    "    ) -> cbsa.01\n",
    "\n",
    "cbsa.01 %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc8d48",
   "metadata": {},
   "source": [
    "Now I will clean up the contents of cbsa.01 so that year is a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd850b2",
   "metadata": {
    "name": "tidy13"
   },
   "outputs": [],
   "source": [
    "cbsa.01 %>%\n",
    "  separate(\n",
    "    col = \"variable\",\n",
    "    into = c(\"vartype\", \"year\"),\n",
    "    sep = \"(?=[[:digit:]])\",\n",
    "    extra = \"merge\",\n",
    "    remove = FALSE\n",
    "  ) -> cbsa.02\n",
    "\n",
    "cbsa.02 %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115c2a3-8682-4840-8ebf-35d37bbf662b",
   "metadata": {},
   "source": [
    "Here, notice that the `sep = ` command looks different. What is this specification here? Well, if you look at the column names we need to flip in __cbsa__, you will notice that the four-digit year does not always start at the same place. Here are the column names ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04633b-4d3e-43fd-98e8-f636951c3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(cbsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8bc9e-d51d-4076-b244-837d39c18bdc",
   "metadata": {},
   "source": [
    "Notice POPESTIMATE, NPOPCHG, BIRTHS, DEATHS, and so on. \n",
    "\n",
    "What we need therefore is to specify where the solumns should be separated, and we do that by saying separate wherever you see the first nuymeric digit appear. This is our `sep = \"(?=[[:digit:]])\"` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97337aa",
   "metadata": {},
   "source": [
    "Now the final flip to wide format, by first omitting the first, third, and four columns, then grouping by NAME and year, and then pivoting wide ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b0b20",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "tidy14"
   },
   "outputs": [],
   "source": [
    "cbsa.02 %>%\n",
    "  select(c(2, 5:7)) %>%\n",
    "  group_by(NAME, year) %>%\n",
    "  pivot_wider(\n",
    "    names_from = \"vartype\",\n",
    "    values_from = \"estimate\"\n",
    "  ) -> cbsa.03\n",
    "\n",
    "cbsa.03 %>%\n",
    "  glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd70208-30c6-4d04-8927-cd247117b569",
   "metadata": {},
   "source": [
    "And there you have it. We are just getting familiar with the heart of `dplyr` and `tidyr`, both written to work well together, and an essential part of any data analysts' toolkit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d1035-54ee-432d-8819-7a0a04024dbe",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31851638",
   "metadata": {},
   "source": [
    "# Exercises for Practice\n",
    "\n",
    "## Exercise 01 \n",
    "Using the `cmhflights` data from last week, create a column that unites the three columns `Year`, `Month`, and `DayofMonth` into a single column that we will name `date_of_flight`. This column should separate the three fields by \"-\". \n",
    "\n",
    "> Hint: You will have to use `load(...)` with `here(...)`.\n",
    "\n",
    "## Exercise 02\n",
    "Sticking with `cmhflights`, separate `OriginCityName` into two new columns, `origin_city` and `origin_state`. Do the same for `DestCityname`, calling the new columns `destination_city` and `destination_state`, respectively. Both city columns should only display the name of the city, while both state columns should only display the abbreviated state name (for example, \"CA\", \"OH\", etc.)  \n",
    "\n",
    "## Exercise 03\n",
    "Tidy the `weather` data such that the resulting data-set, called `wdf`, has the `days` (the d1-d31 columns) as rows and `TMIN` and `TMAX` as columns. The end result should be as shown below:\n",
    "\n",
    "| id  | year | month | day | TMIN | TMAX |\n",
    "| :-- | :--  | :--   | :-- | :--  | :--  |\n",
    "| MX000017004 | 2010 | 1 | d1 | NA | NA |\n",
    "| MX000017004 | 2010 | 1 | d2 | NA | NA |\n",
    "| MX000017004 | 2010 | 1 | d3 | NA | NA |\n",
    "| MX000017004 | 2010 | 1 | d4 | NA | NA |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282a6c0-ee11-4859-b3a2-cb8ffd9de50c",
   "metadata": {},
   "source": [
    "The data can be accessed as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e82373",
   "metadata": {
    "name": "tiyex01"
   },
   "outputs": [],
   "source": [
    "read.delim(\n",
    " file = \"http://stat405.had.co.nz/data/weather.txt\",\n",
    " stringsAsFactors = FALSE\n",
    " ) -> weather\n",
    "\n",
    "weather"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,include,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
